{"posts":[{"title":"CentOS7更换阿里&#x2F;清华源","text":"Blog网址：https://www.cnblogs.com/wswind/p/10173591.html","link":"/2024/04/23/CentOS7%E6%9B%B4%E6%8D%A2%E9%98%BF%E9%87%8C-%E6%B8%85%E5%8D%8E%E6%BA%90/"},{"title":"Axure RP 9 产品设计入门","text":"🚪Axure RP 9 产品设计入门Axure RP 9 软件的安装可以直接官网下载，然后去某宝买一个账号的激活码，详情不再赘述，可以自行 Bing。下载网址：https://www.axure.com/release-history/rp9学习参考视频：https://www.bilibili.com/video/BV1hU4y1L77u/ Axure 软件的一些基础设置 偏好设置 文件 → Preferences（首选项、偏好设置） 网格设置 视图设置 → 标尺·网格·辅助线 → 网格设置 我个人认为舒服的设置：网格对齐，间距 10 像素，样式更改为线段，颜色 #F2F2F2 如何预览、发给别人可以浏览的文件发布 → 生成 HTML 文件（选择一个文件夹，会生成很多文件，因此最好选择一个独立的文件夹） 常用的设计尺寸手机端：365*667 开始设计绘制一个简单的UI界面 用矩形绘制一个背景：使用线性方式填充 用水平线绘制隔断 用矩形绘制按钮 如何绘制按钮使用矩形绘制一个按钮 绘制矩形 右键矩形 → 交互样式 美化输入框 绘制矩形 Ctrl + D 复制一份，调整大小 添加输入框和一个搜索图标 母版选择绘制好的组件，右键选择转换为母版 单选框的使用和自定义单选框（美化操作）使用单选框时，需要对单选框进行编组。编组方式：框选对应组的单选框，右键选择指定单选按钮的组，然后命名组名即可。自定义单选框操作步骤： 使用圆形绘制一个大圆以及一个小圆 内部的小圆的线条和填充设置为透明 右键添加交互样式，设置当选中时，内部小圆的填充和线条更改颜色，外部大圆线条更改颜色 添加文字后进行编组，对于编组内容设置交互（和交互样式不同），在菜单栏的右侧，交互面板 效果如下： 常用工具页面工具 页面工具中可以创建多个页面 页面工具中可以按住 Ctrl + 左右方向键 来调整页面的级别 页面工具中可以按住 Ctrl + 上下方向键 来调整页面的顺序 概要工具 概要工具可以看到整个页面全部的元件 当存在遮罩关系时，可以选择概要工具中需要修改的元件，不需要破坏遮罩关系 可以通过筛选按钮来对元件进行筛选 建议给元件起好名字 钢笔工具 世上无难事，只怕有心人 使用钢笔工具来绘制自定义图案 绘制复杂的UI界面 常用的交互事件及操作页面跳转 页面跳转原理：事件 → 动作 → 目标 对于跳转来说：事件（点击） → 动作（跳转） → 目标（页面2） 事件的选择在“交互”面板处（注：不是交互样式） 实现时点击右侧交互面板新建交互，选择单击时，动作设置为打开链接，目标设置为要切换到的界面 当点击预览时候，会发现元件的显示往往出现在屏幕中心位置，如果想要让元件按照画布的绝对位置显示，可以点击页面，选择样式中的“页面排列”，在其中调整相关显示样式。 热区 为什么使用热区？ 对于图片中的情况，如果我们想点击按钮完成跳转操作，可以直接给使用方式 ① 按钮添加一个交互事件。 但是当我们想要点击这个区域时进行跳转，一个元件一个元件添加事件过于繁琐（技巧：可以通过 Ctrl + C 在右侧交互面板直接复制整个事件，然后点击想要添加该事件的元件，通过 Ctrl + V 粘贴到元件上），而且不方便后续的修改。 于是可以使用方式 ② 将要整个部分编组，然后为整个组添加事件。但是当我们因为某种原因破坏了整个组时，可能会遗忘添加事件，导致整个事件消失。 所以热区就是为了解决上面的问题，我们可以通过方式 ③ 给组件添加热区，只要点击这个区域即可完成指定事件。 且热区占用内存更小。 显示和隐藏设置文字设置某元件上的文字 设置选中设置一个元件为选中状态 启用或禁用 启用/禁用是针对于一个元件 常用场景是：当满足某条件时启用/禁用某元件 例如：当用户输入账号和密码后启用登录按钮（瞎编的），当用户同意协议才可进行下一步这种 移动 移动一个元件，可以在“移动”处设置经过（相对位置）、到达（绝对位置）来移动元件 等待 有时候等待看起来并不生效，需要观察是否是等待动作前的动作设置了动画。 例如：移动动作设置了 500ms 的动画，其实移动动作是瞬间完成的，动画只是一种呈现的方式。所以动画呈现的效果和等待是几乎同时进行的（“移动”动作设置 500ms 的动画和 500ms 的“等待”，动画开始播放时“等待”同时进行，动画结束播放时，“等待”结束）。 旋转设置尺寸设置透明度制作更复杂的动效 Axure RP 9 的动画效果是可以叠加的。 等待可以分割两个本来融合的叠加效果。 使用该上图所示的操作，会导致“移动”和“旋转”的融合无法叠加，先执行“移动”，再执行“旋转”。 文本框的长度是可以固定或者跟随的，当文本框样式如下时，则说明文本框此时的长度是固定的。此时可以双击两侧中间的锚点来使文本框变为跟随模式。下图为固定长度：下图为跟随长度：双击角上的锚点可以设置是否跟随高度、宽度（若不跟随，则此时文本框高度和宽度完全固定）。 复杂动效总体流程： 滚动到元件想要动画展示，一般设置动画的时间为 500ms，但是对于用户来说，500ms 看起来有些卡顿，所以 350ms 往往是个不错的选择 更多事件 事件 条件 备注 单击时 点击形状时 一般单击事件不能和“鼠标按下”/“鼠标松开” 事件同时使用 双击时 双击形状时 鼠标右击时 形状的上下文菜单被触发时（右键点击形状时候） 鼠标按下时 鼠标在形状上按下时 鼠标松开时 鼠标在形状上松开时 鼠标移动时 鼠标移动到形状上时 鼠标移入时 鼠标指针进入形状元件区域中时 鼠标移出时 鼠标指针离开形状元件区域中时 鼠标停放时 鼠标指针在停放在形状上超过 1s 时 鼠标长按时 鼠标指针在按压在形状上超过 1s 时 按键按下时 当焦点在形状上并按下键盘上的任意按键时 按键松开时 当焦点在形状上并按下键盘上的任意按键松开时 移动时 当形状发生移动时 旋转时 当形状发生旋转时 尺寸改变时 当形状尺寸发生改变时 显示时 当形状发生显示时 隐藏 当形状发生被隐藏时 获取焦点时 当形状获取焦点时 失去焦点时 当形状失去焦点时 选中 当形状被选中时 取消选中时 当形状取消选中时 选中改变时 当形状的选中状态发生改变时 载入时 形状已加载时（首次显示页面时） 更多动作内部框架 若概念不明确，往往会将内部框架和快照混淆。 快照往往用于在一个页面预览所有的页面，点击快照后跳转到快照包含的页面，并且在跳转后的页面进行修改。 而内部框架和快照不同，内部框架相当于将需要包含的页面复制了一份，粘贴到了内部框架中，因此可以直接在内部框架中修改内容，修改内部框架中的内容不会影响原页面内容。 动态面板 动态面板也是一个元件，也可以显示或隐藏。 我们可以将动态面板形象的理解为一个盒子。在盒子里没有东西时，动态面板“无色无味”，看不见摸不到，双击后可以键入盒子内部。 盒子内部也可以添加很多层： 我们可以通过一个按钮，添加“设置动态面板”动作来切换层，因此我们可以想到动态面板常用于实现轮播图（当然还有很多其他的玩法） 动态面板案例 1：遮罩使用动态面板可以实现遮罩的一些操作，如： 超出指定范围的元件可以使用动态面板，隐藏超出部分，右键直接将元件转换为动态面板即可： 将元件一直固定再某一位置选择固定到浏览器，并且进一步选择固定位置，当浏览器页面过长需要滚动时，动态面板的位置不会发生改变。 通栏选择 “100%宽度（仅浏览器中有效）”，即可将动态面板的宽度按照浏览器的宽度进行设置，也就是所谓的通栏（Banner，Banner也可以用来表示轮播图） 动态面板是可以嵌套的 动态面板案例 2：浮窗 动态面板案例 3：弹窗 动态面板案例 4：轮播 动态面板案例 5：Tab切页 动态面板案例 6：列表切页 动态面板案例 7：拖动 使用动态面板实现拖动的难点在于使用“动态面板的嵌套”和“设置边界” 使用动态面板的嵌套是为了防止直接拖动最外层的动态面板，而是拖动动态面板内部的一个面板。 使用边界的难点在于 Axure RP 9 在设计这个功能时的让人难以理解。这里简单的理解是： 对于“左侧”，$-35 &lt;= x &lt;= 0$ 对于“左侧”可以移动 0 像素或移动 -35 像素 对于“左侧”，可以不移动，或者向左移动 35 像素 用不熟练的时候多尝试 中继器 添加局部变量的方式： 首先点击添加局部变量 变量全局变量可以跨页面传参 判断 添加判断当添加交互事件时，不进一步选择动作，而是选择“启用情形”，在启用情形中添加判断。 局部变量获取元件位置，结合判断可以用 [[元件局部变量.x]] 获取元件的 x 位置 多条件判断多条件判断可以通过在“添加情形”部分添加行来增加判断条件，“匹配所有”和“匹配任何”两个情况，分别代表的是 and 和 or。 嵌套判断 案例：绘制注册 中间页","link":"/2024/04/12/Axure-RP-9-%E4%BA%A7%E5%93%81%E8%AE%BE%E8%AE%A1%E5%85%A5%E9%97%A8/"},{"title":"[20240412] 下一步计划","text":"[Date: 20240412] 下一步计划[TOC] 📕 计划 1: 学习 Axure RP 9[*注] 2024.04.20 该计划已经完成主要是为了计划2做准备 📕 计划 2: 开发计划开发一个好玩的小工具这个其实是一个奇思妙想啦，目前还不知道能不能实现，总的来说就是希望用户上传一张文件，然后我们转化成命令行图片。就例如我用的网站博客的框架，他能用符号绘制一个很好看终端欢迎界面，我觉得是一个很有意思的东西，所以我准备在接下来的一年时间里实现这个小工具。目前连文件夹都没有创建，哈哈哈 :P 12345678INFO ======================================= ██╗ ██████╗ █████╗ ██████╗ ██╗ ██╗███████╗ ██║██╔════╝██╔══██╗██╔══██╗██║ ██║██╔════╝ ██║██║ ███████║██████╔╝██║ ██║███████╗ ██║██║ ██╔══██║██╔══██╗██║ ██║╚════██║ ██║╚██████╗██║ ██║██║ ██║╚██████╔╝███████║ ╚═╝ ╚═════╝╚═╝ ╚═╝╚═╝ ╚═╝ ╚═════╝ ╚══════╝============================================= 使用 QT 6 开发一个好玩的桌面端应用刷抖音的时候看到了，一些很好玩的评论，因为大家好像觉得小红书是一个给女孩子交流的平台，所以男孩子也希望有一个自己交流的平台，大概就是小蓝书的样子。这也是个很大的项目了，需要很长时间设计，不过最起码要等我学完Axure RP 9 吧，当然肯定不是全部实现，我就是想边学边开发，能做多少是多少的样子。 📕 计划 3: 读书📕 计划 4: 复习数据结构与算法复习的列表会开一篇新博客来归档","link":"/2024/04/12/20240412-%E4%B8%8B%E4%B8%80%E6%AD%A5%E8%AE%A1%E5%88%92/"},{"title":"PyTorch快速上手指南","text":"PyTorch 深度学习框架快速上手指南PyTorch 可以说是目前最常用的深度学习框架 , 常应用于搭建深度学习网络 , 完成一些深度学习任务 (CV、NLP领域) 要想快速上手 PyTorch , 你需要知道什么 : 一个项目的完整流程 , 即到什么点该干什么事 几个常用 (或者说必备的) 组件 剩下的时间你就需要了解 , 完成什么任务 , 需要什么网络 , 而且需要用大量的时间去做这件事情 $^{(e.g.)}$例如 : 你现在有一个图像分类任务 , 完成该任务需要什么网络, 你需要通过查找资料来了解需要查找什么网络。 需要注意的是 , 有一些常识性的问题你必须知道 , 例如: 图像层面无法或很难使用机器学习方法 , 卷积神经网络最多的是应用于图像领域等 下面我将通过一个具体的分类项目流程来讲述到什么点该干什么事一个完整的 PyTorch 分类项目需要以下几个方面: 准备数据集 加载数据集 使用变换(Transforms模块) 构建模型 训练模型 + 验证模型 推理模型 准备数据集 一般来说 , 比赛会给出你数据集, 不同数据集的组织方式不同 , 我们要想办法把他构造成我们期待的样子 分类数据集一般比较简单, 一般是将某个分类的文件全都放在一个文件夹中, 例如: 二分类问题 : Fake(文件夹) / Real(文件夹) 多分类问题 : 分类 1(文件夹) / 分类 2(文件夹) / … / 分类 N(文件夹) 当然有些时候他们会给出其他方式 , 如 UBC-OCEAN , 他们将所有的图片放在一个文件夹中 , 并用 csv 文件存储这些文件的路径(或者是文件名) , 然后在 csv 文件中进行标注(如下): 以后你可能还会遇到更复杂的目标检测的数据集, 这种数据集会有一些固定格式 , 如 VOC格式 , COCO格式等 在数据集方面 , 需要明确三个概念——训练集、验证集和测试集 , 请务必明确这三个概念 , 这是基本中的基本 训练集(Train) : 字如其名 , 简单来说就是知道数据 , 也知道标签 的数据 , 我们用其进行训练 验证集(Valid) : 验证集 和 测试集 是非常容易混淆的概念 , 简单来说 , 验证集就是我们也知道数据和标签 , 但是我们的一般不将这些数据用于训练 , 而是将他们当作我们的测试集 , 即我们已经站在了出题人的角度 , 给出参赛者输入数据 , 而我们知道这个数据对应的输出 , 但是我们不让模型知道 测试集(Test) : 测试集就是 , 我们不知道输入数据的输出标签 , 只有真正的出题人知道 , 一般来说 , 我们无法拿到测试集 , 测试集是由出题人掌控的 需要注意的是 , 如果你通过某种途径知道了所有的测试集的标签时 , 不可使用测试集进行训练 , 这是非常严重的学术不端行为 , 会被学术界和工业界唾弃 1234567891011# 现在我们已经有了一个数据集 , 我将以 FAKE_OR_REAL 数据集为例 , 展示我们数据集的结构# D:\\REAL_OR_FAKE\\DATASET# ├─test --------- 测试集路径, 这里可以放你自己的数据, 你甚至可以将他们分类, 但是请注意, 实际情况下你只能通过这种方式来“得到”测试集# │ ├─fake ------ 你自己分的类, 开心就好# │ └─real ------ 同上# ├─train -------- 训练集路径, 这里面放的是题目给出的数据, 下面有 fake 和 real 两个文件夹, 这两个文件夹中就是两个类别, 我们要用这里面的图片进行分类 # │ ├─fake# │ └─real# └─valid -------- 验证集路径, 这里面放的是题目给出的数据, 下面有 fake 和 real 两个文件夹, 这两个文件夹中就是两个类别, 这里面的图片不需要进行训练# ├─fake# └─real 加载数据集 请务必记住 , 不管是什么数据集 , 数据集是如何构成的 , 在使用 PyTorch 框架时 , 我们都要像尽办法将他们加载入 Dataset 类中 简单来说 , Dataset 类就是描述了我们数据的组成的类 需要注意 , PyTorch 实现了许多自己的 Dataset 类 , 这些类可以轻松的加载特定格式的数据集 , 但是我强烈建议所有的数据集都要自己继承Dataset类 , 自行加载 , 这样我们可以跟清晰的指导数据集的组成方式 , 也可以使得我们加载任意格式的数据集 实现 DataSet 类需要我们先继承 Dataset 类 , 在继承 Dataset 类后, 我们只需要实现其中的__init__、__len__和__getitem__三个方法 , 即可完成对数据集的加载 , 这三个方法就和他的名字一样 : __init__ 方法是构造函数 , 用于初始化 __len__ 方法用于获取数据集的大小 __getitem__ 方法用于获取数据集的元素 , 我将从下面的代码中进行更详细的解释 有些数据集并不分别提供 Train训练集 和 Valid验证集, 我们可以使用 random_split() 方法对数据集进行划分 需要注意的是, 每次重新划分数据集时, 必须重新训练模型, 因为 random_split() 方法随机性, 划分后的数据不可能和之前的数据完全重合, 因此会导致数据交叉的情况, 下面一段使用 random_split() 进行划分的 Python 代码示例 : 12345678# 下面演示使用 random_split 来划分数据集的操作# 我们假设已经定义了 CustomImageDataSetsplit_ratio = 0.8 # 表示划分比例为 8 : 2dataset = CustomImageDataSet(fake_dir, real_dir) # 定义 CustomImageDataSet 类, 假设此时没有划分训练集和验证集train_dataset_num = int(dataset.lens * split_ratio) # 定义训练集的大小valid_dataset_num = dataset.lens - train_dataset_num # 定义验证集的大小# random_split(dataset, [train_dataset_num, valid_dataset_num]) 表示将 dataset 按照 [train_dataset_num: valid_dataset_num] 的比例进行划分train_dataset, valid_dataset = random_split(dataset, [train_dataset_num, valid_dataset_num]) 当数据集不是很大的时, 推荐人为的将数据集进行划分, 可以写一个 Python 脚本(.py) 或者 批处理脚本(.bat) 来完成这个操作 完整的数据集加载代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import torchfrom torch.utils.data import Datasetimport osfrom PIL import Image# 这里我们定义了一个 CustomImageDataset(...) 类, 括号中的内容表示我们继承了 ... 类# 因此我们这里 CustomImageDataset(Dataset): 表示我们定义了一个“自定义图片”类, 这个“自定义图片”类继承自 Dataset 类class CustomImageDataset(Dataset): # 这里我们实现 __init__ 方法, __init__ 方法其实就是一个类的构造函数, 他也分有参构造和无参构造, 只是在这里我们说无参构造基本没啥意义 # 因此我们常常实现这个类, 使得可以指定这个类的输入输出 # 比如下面我们写的 def __init__(self, fake_dir, real_dir, transform=None): # self : 自己, 我一般直接理解为 this 指针, 如果有兴趣了解更深层的东西可以查阅一些资料, 这个是必填的 # fake_dir : 用于指定 fake 类型图片的位置的 # real_dir : 用于指定 real 类型图片的位置的 # transform : 用于指定变换, 简单来说就是对输入进行某些操作, 我会在下面的板块中进行详细叙述 def __init__(self, fake_dir, real_dir, transform=None): self.fake_dir = fake_dir # 这里表示这个类内定义了一个 fake_dir, 其值为传入的 fake_dir self.real_dir = real_dir # 这里表示这个类内定义了一个 real_dir, 其值为传入的 real_dir self.transform = transform # 这里表示这个类内定义了一个 transform, 其值为传入的 transform, 当没有传入时, 这个变量为 None self.fake_images = os.listdir(fake_dir) # 传入的 fake_dir 是一个路径, 我们使用 os.listdir(fake_dir) 可以加载 fake_dir 文件夹下的内容, 也就是所有 fake 图片 self.real_images = os.listdir(real_dir) # 传入的 real_dir 是一个路径, 我们使用 os.listdir(real_dir) 可以加载 real_dir 文件夹下的内容, 也就是所有 real 图片 self.total_images = self.fake_images + self.real_images # 总图片列表, 就是将 fake 图片列表和 real 图片列表进行组合 self.labels = [0]*len(self.fake_images) + [1]*len(self.real_images) # 对图片打标签, fake 为 0, real 为 1 # [0] * 10 得到的结果为 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0] # [1] * 10 得到的结果为 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1] # 这里我们实现 __len__ 方法, 这个方法用于获取数据集的大小 def __len__(self): return len(self.total_images) # 这里我们直接返回总图片列表的长度即可, 这里的实现方式不唯一, 只要能做到表示数据集大小即可 # 这里我们实现 __getitem__ 方法, 这个方法用于获取数据集中的某个元素 # 其中 idx 表示索引, 这个参数是必须的, 当然可以起其他名字, 不过最好还是使用 idx # __getitem__(self, idx) 表示获取 idx 位置的元素 def __getitem__(self, idx): # 这里表示获取一个元素的逻辑 # 当 idx 位置的标签为 0 时, 图片的路径为 fake_dir + self.total_images[idx], idx 即为图片的索引位置 # 当 idx 位置的标签为 1 时, 图片的路径为 real_dir + self.total_images[idx] image_path = os.path.join(self.fake_dir if self.labels[idx] == 0 else self.real_dir, self.total_images[idx]) # 使用 PIL 库加载图片, 通过 image_path 打开图片, 并且将图片转化为 RGB 格式 image = Image.open(image_path).convert('RGB') # 这里是 transform, 表示变换, 当其值为 None 时不进行操作, 当传入自己的 transform 时即为非空, 即对输入数据进行变换 if self.transform: # 我们将变换后的图片直接保存在原位置 image = self.transform(image) # 最后函数的返回值为 image 和 self.labels[idx], 即表示索引位置 idx 处的图片和标签 return image, self.labels[idx] 使用 Transforms 不要简单的使用原始图片进行训练 , 当然如果一定要使用原始图片进行训练, 也可以使用 transforms 模块 一般来说, 训练集和验证集的 transforms 是不同的, 因为我们希望验证集和测试集的图片贴合真实的情况 下面的代码演示了如何定义 transforms 在定义完 transforms 我们就可以完全定义我们的 Dataset 和 Dataloader 了 123456789101112131415161718192021222324252627282930import torchfrom torchvision import transforms# 定义transform# transforms.Compose(transforms) 实际上就是将多个 transform 方法变为逐步执行, 一般我们直接使用这种方式来对图片进行连续的变换train_transform = transforms.Compose([ transforms.RandomHorizontalFlip(), # 随机水平翻转 transforms.RandomVerticalFlip(), # 随机垂直翻转 transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1), # 改变图像的属性, 将图像的brightness亮度/contrast对比度/saturation饱和度/hue色相 随机变化为原图亮度的 10% transforms.RandomResizedCrop(224, scale=(0.8, 1.0)), # 对图片先进行随机采集, 然后对裁剪得到的图像缩放为同一大小, 意义是即使只是该物体的一部分, 我们也认为这是该类物体 transforms.RandomRotation(40), # 在[-40, 40]范围内随机旋转 transforms.RandomAffine(degrees=0, shear=10, scale=(0.8,1.2)), # 随机仿射变换 transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # 色彩抖动 transforms.ToTensor(), # [重点] 将图片转化为 Tensor 张量, 在 PyTorch 中, 一切的运算都基于张量, 请一定将你的输入数据转化为张量 # 请理解什么是张量 : 我们在线性代数中有向量的概念, 简单来说就是张量就是向量, 只不过张量往往具有更高的维度 # 而大家一般习惯将高于三维的向量称为张量, 某些人(比如我)也习惯所有的向量统称为张量 # 可以简单的将数组的维数来界定张量的维度 # 例如 [ ] 为一维张量, [[ ]] 为二维张量, [[[ ]]]为三维张量, [[[[ ]]]]为四维张量 # 对于图像来说, jpg 图像实际为三维矩阵, png 图像实际为四维矩阵, 这个维数是根据图像的通道数进行划分的 # 例如 jpg 有 R、G、B三个通道, png 具有 transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # 归一化, 可以对矩阵进行归一化 # 详细查看这个Blog : https://blog.csdn.net/qq_38765642/article/details/109779370 transforms.RandomErasing() # 随机擦除])valid_transform = transforms.Compose([ transforms.Resize((256, 256)), # Resize 操作, 将图片转换到指定的大小 transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]) 12345678910111213141516171819from torch.utils.data import DataLoader# 定义 Dataset 实例train_dataset = CustomImageDataset(fake_dir=&quot;./dataset/train/fake&quot;, real_dir=&quot;./dataset/train/real&quot;, transform=train_transform)valid_dataset = CustomImageDataset(fake_dir=&quot;./dataset/valid/fake&quot;, real_dir=&quot;./dataset/valid/real&quot;, transform=valid_transform)# 创建 DataLoader 实例# 这里将要涉及到超参数的概念, 什么是超参数: 简单来将, 超参数就是我们自己能指定的一些数据, 超参数的选择将很大程度上影响模型的性能# 因此 深度学习领域的工程师 常称自己为 炼丹师、调参师等batch_size = 32 # batch_size 就是一个超参数, batch 即为 “批次”, 表示一次使用 DataLoader 加载多少张图片进行运算 # 这个数值并不是越大越好, 也不是越小越好, 但是往往大一些比较好, 这个数字最大能选择多大和你的图片大小和显卡显存有很大的关系 # 当出现 [Out Of Memery] 错误时往往表明你选取了过大的 batch_size, 导致显卡出现了爆显存的问题# batch_size : 每次训练时，模型所看到的数据数量。它是决定训练速度和内存使用的重要参数。# shuffle : 是否在每个训练周期之前打乱数据集的顺序。这对于许多模型（如卷积神经网络）是很有帮助的，因为它可以帮助模型避免模式识别。# sampler : 定义如何从数据集中抽样。默认情况下，它使用随机采样。但你可以使用其他更复杂的采样策略，如学习率调度采样。# batch_sampler : 与sampler类似，但它在批处理级别上进行采样，而不是在整个数据集上。这对于内存使用效率更高的场景很有用。# num_workers : 定义了多少个工作进程用于数据的加载。这可以加快数据加载的速度，但需要注意内存的使用情况。train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False) 1234567891011# 查看Dataloader数据# 为了了解Dataloader中的数据, 我们可以使用以下方法来查看:# 使用 Python 的 len() 函数 : 我们可以直接通过 len() 函数获取 Dataloader 的长度, 即数据集中数据块的数量# 使用 torch.utils.data.DataLoader.len() 方法 : 这个方法也会返回Dataloader的长度。# 使用 iter() 函数：Dataloader是一个可迭代对象，我们可以直接通过iter()函数对其进行迭代，以获取每个批次的数据。# 使用torchvision.utils.save_image()函数 : 如果我们正在处理的是图像数据集，那么可以使用这个函数来保存Dataloader中的图像数据。 len(train_loader) # 401len(valid_loader) # 100images, labels = next(iter(train_loader))print(images)print(labels) 构建模型 构建模型是比较重要的一部分, 一般来说做好数据集之后, 最重要的事情就是修改模型, 通过训练结果改进模型, 判断自己的模型的正确性, 这里就是整个你要用到的神经网络的部分 , 需要注意的是 , 这里指定什么输入 , 推理的时候就要指定什么输入 简单用几个符号说明一下就是: $^{Train} model (inputX, inputY, …)$ → $^{Valid} model (inputX, inputY, …)$ 如何确定输入是什么: 看 forward() 的输入是啥模型的输入就是啥 我下面展现了我复现的 ResNet50 , 用这种方式可以顺便教你如何复现网络结构 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140import torch.nn as nnfrom torch.nn import functional as F# 这里是对 ResNet50 的实现, 请对照论文来进行对照阅读# 定义 ResNet50Basic类, 这里并不是完整的模型, 而是模型的一个部分class ResNet50BasicBlock(nn.Module): def __init__(self, in_channel, outs, kernerl_size, stride, padding): # super(ResNet50BasicBlock, self).__init__() 这里是干什么的? # 1. 首先找到 ResNet50BasicBlock 的父类, 这里是 nn.Module # 2. 把类 ResNet50BasicBlock 的对象self转换为 nn.Module 的对象 # 3. &quot;被转换&quot;的 nn.Module 对象调用自己的 init 函数 # 简单理解一下就是 : 子类把父类的 __init__ 放到自己的 __init__ 当中, 这样子类就有了父类的 __init__ 的那些东西 super(ResNet50BasicBlock, self).__init__() # 这里只是定义部分, 在这里的定义并不一定会在推理过程中使用 self.conv1 = nn.Conv2d(in_channel, outs[0], kernel_size=kernerl_size[0], stride=stride[0], padding=padding[0]) self.bn1 = nn.BatchNorm2d(outs[0]) self.conv2 = nn.Conv2d(outs[0], outs[1], kernel_size=kernerl_size[1], stride=stride[0], padding=padding[1]) self.bn2 = nn.BatchNorm2d(outs[1]) self.conv3 = nn.Conv2d(outs[1], outs[2], kernel_size=kernerl_size[2], stride=stride[0], padding=padding[2]) self.bn3 = nn.BatchNorm2d(outs[2]) # 输入是啥看 forward(), 例如这里是 forward(self, x), 则表示输入是 x, 也就是一个 def forward(self, x): # nn.Conv2d 是卷积层, 请了解[1]什么是卷积层, 以及[2]卷积层是干啥用的, [3]卷积后会变成什么 # 卷积运算的目的是提取输入的不同特征, 第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级, 更多层的网路能从低级特征中迭代提取更复杂的特征 out = self.conv1(x) # [*] 什么是 ReLU, ReLU是激活函数, 请了解 [1]什么是激活函数, [2]为什么要使用激活函数 # [*] 什么是 Batch Normalization层, BN 层是批次归一化层 out = F.relu(self.bn1(out)) out = self.conv2(out) out = F.relu(self.bn2(out)) out = self.conv3(out) out = self.bn3(out) return F.relu(out + x)# 定义 ResNet50DownBlock类, 这里并不是完整的模型, 而是模型的一个部分class ResNet50DownBlock(nn.Module): def __init__(self, in_channel, outs, kernel_size, stride, padding): super(ResNet50DownBlock, self).__init__() self.conv1 = nn.Conv2d(in_channel, outs[0], kernel_size=kernel_size[0], stride=stride[0], padding=padding[0]) self.bn1 = nn.BatchNorm2d(outs[0]) self.conv2 = nn.Conv2d(outs[0], outs[1], kernel_size=kernel_size[1], stride=stride[1], padding=padding[1]) self.bn2 = nn.BatchNorm2d(outs[1]) self.conv3 = nn.Conv2d(outs[1], outs[2], kernel_size=kernel_size[2], stride=stride[2], padding=padding[2]) self.bn3 = nn.BatchNorm2d(outs[2]) self.extra = nn.Sequential( nn.Conv2d(in_channel, outs[2], kernel_size=1, stride=stride[3], padding=0), nn.BatchNorm2d(outs[2]) ) def forward(self, x): x_shortcut = self.extra(x) out = self.conv1(x) out = self.bn1(out) out = F.relu(out) out = self.conv2(out) out = self.bn2(out) out = F.relu(out) out = self.conv3(out) out = self.bn3(out) return F.relu(x_shortcut + out)class ResNet50(nn.Module): def __init__(self): super(ResNet50, self).__init__() self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3) self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) # Sequential 类是 torch.nn 模块中的一个容器, 可以将多个层封装在一个对象中, 方便顺序连接 self.layer1 = nn.Sequential( ResNet50DownBlock(64, outs=[64, 64, 256], kernel_size=[1, 3, 1], stride=[1, 1, 1, 1], padding=[0, 1, 0]), ResNet50BasicBlock(256, outs=[64, 64, 256], kernerl_size=[1, 3, 1], stride=[1, 1, 1, 1], padding=[0, 1, 0]), ResNet50BasicBlock(256, outs=[64, 64, 256], kernerl_size=[1, 3, 1], stride=[1, 1, 1, 1], padding=[0, 1, 0]), ) self.layer2 = nn.Sequential( ResNet50DownBlock(256, outs=[128, 128, 512], kernel_size=[1, 3, 1], stride=[1, 2, 1, 2], padding=[0, 1, 0]), ResNet50BasicBlock(512, outs=[128, 128, 512], kernerl_size=[1, 3, 1], stride=[1, 1, 1, 1], padding=[0, 1, 0]), ResNet50BasicBlock(512, outs=[128, 128, 512], kernerl_size=[1, 3, 1], stride=[1, 1, 1, 1], padding=[0, 1, 0]), ResNet50DownBlock(512, outs=[128, 128, 512], kernel_size=[1, 3, 1], stride=[1, 1, 1, 1], padding=[0, 1, 0]) ) self.layer3 = nn.Sequential( ResNet50DownBlock(512, outs=[256, 256, 1024], kernel_size=[1, 3, 1], stride=[1, 2, 1, 2], padding=[0, 1, 0]), ResNet50BasicBlock(1024, outs=[256, 256, 1024], kernerl_size=[1, 3, 1], stride=[1, 1, 1, 1], padding=[0, 1, 0]), ResNet50BasicBlock(1024, outs=[256, 256, 1024], kernerl_size=[1, 3, 1], stride=[1, 1, 1, 1], padding=[0, 1, 0]), ResNet50DownBlock(1024, outs=[256, 256, 1024], kernel_size=[1, 3, 1], stride=[1, 1, 1, 1], padding=[0, 1, 0]), ResNet50DownBlock(1024, outs=[256, 256, 1024], kernel_size=[1, 3, 1], stride=[1, 1, 1, 1], padding=[0, 1, 0]), ResNet50DownBlock(1024, outs=[256, 256, 1024], kernel_size=[1, 3, 1], stride=[1, 1, 1, 1], padding=[0, 1, 0]) ) self.layer4 = nn.Sequential( ResNet50DownBlock(1024, outs=[512, 512, 2048], kernel_size=[1, 3, 1], stride=[1, 2, 1, 2], padding=[0, 1, 0]), ResNet50DownBlock(2048, outs=[512, 512, 2048], kernel_size=[1, 3, 1], stride=[1, 1, 1, 1], padding=[0, 1, 0]), ResNet50DownBlock(2048, outs=[512, 512, 2048], kernel_size=[1, 3, 1], stride=[1, 1, 1, 1], padding=[0, 1, 0]) ) self.avgpool = nn.AvgPool2d(kernel_size=7, stride=1, ceil_mode=False) # self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1)) self.fc = nn.Linear(2048, 10) # 使用卷积代替全连接 self.conv11 = nn.Conv2d(2048, 10, kernel_size=1, stride=1, padding=0) def forward(self, x): out = self.conv1(x) out = self.maxpool(out) out = self.layer1(out) out = self.layer2(out) out = self.layer3(out) out = self.layer4(out) # avgpool 平均池化层, 了解什么是平均池化层 out = self.avgpool(out) out = self.conv11(out) out = out.reshape(x.shape[0], -1) # out = self.fc(out) return out# 这里展现了对 ResNet 的一个具体的应用# x = torch.randn(1, 3, 224, 224) # 这个是我们 ResNet50 期待的输入样子, 可以看到他是 [1] 个 [3] 通道, 宽度为[224], 高度为 [224]的张量 image_path = './dataset/test/fake/test_fake_1.png'image = Image.open(image_path).convert('RGB') # 图片加载transform = transforms.ToTensor() # 将图片转化为张量, 此时的 张量的形状为[3, 1024, 1024]# 当输入数据的维度不足时, 我们可以通过 unsqueeze() 添加维度, 这个东西简单理解一下就是, 在某个维度外面加括号[], 即可拓展出更高的维度img_tensor = transform(image).unsqueeze(dim=0)# print(x.shape) 我们可以使用 shape 来查看一个张量的形状# print(img_tensor.shape)# 这里加载我们的网络架构net = ResNet50()# 这里进行输入, 输入 img_tensor, 进入 forword() 部分, 然后得到最终输出的结果out = net(img_tensor)print(out) 1234567891011121314151617181920212223242526import torchfrom torchvision import models# 这里为了方便, 我们直接加载 PyTorch 预训练好的 ResNet50 的模型# PyTorch 已经为我们提供了不少已经预训练好的模型, 我们只需要加载他们与训练好的模型即可# 但是我还是希望你可以掌握上面这种自定义模型的方法, 这样遇到 PyTorch 未提供的模型, 我们也可以尝试自己实现该模型model = models.resnet50(pretrained=True)# 冻结参数 : 即不更新模型的参数# 可以看到下面的代码, 这里表示冻结了所有层for param in model.parameters(): param.requires_grad = False# 但是我们可以通过替换层来接触某些层的冻结num_ftrs = model.fc.in_features # 这里是获取 ResNet50 的 fc 层的输入特征数model.fc = torch.nn.Linear(num_ftrs, 2) # 这里是对 fc 层进行修改, Linear(input_feather_num, output_feather_num) # 这里输入特征数是 num_ftrs, 输出特征数为 2 # 这一行很重要, 指定了模型的位置, cuda 可以理解为 GPU 设备, cuda: 0 表示使用编号为 0 的GPU进行训练# 当有多块 GPU 时, 可以用其他的方式指定 GPU# model = torch.nn.DataParallel(model, device_ids=[0, 1, 2]), 当然向我们这种小白(穷B), 当然还是单卡为主# 为了避免出现多卡的情况, 我在下面放入两篇博客, 有兴趣可以参考这两篇文章进行多卡训练# https://zhuanlan.zhihu.com/p/102697821# https://blog.csdn.net/qq_34243930/article/details/106695877device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)model = model.to(device) 训练模型 + 验证模型 这里需要直接对模型进行训练 , 一般来说 , 在训练的过程中我们会加入 tqdm 库使得训练过程可视化 , 有时我们还会在训练过程中保存更好的训练结果 , 并且设置断点训练等操作 , 我只使用最简单的方式进行预测 train 部分的代码因人而异, 基本上每个人的写法都可能不同, 没有固定的写法 对于训练完的模型我们需要对其进行评价, 一般来说, 训练和验证都是放在一起的, 不可分开的 记得保存一下训练后的模型, 使用如下代码保存/加载整个模型123456# 保存模型model_path = &quot;xxxx.pth&quot; # xxxx 表示一个你喜欢的名字torch.save(model, model_path) # 使用 torch.save(model, model_path) 保存模型# 加载模型model = torch.load(model_path) # 使用 torch.load(model_path) 即可加载模型 完整的”训练模型 + 验证模型”代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970from tqdm import tqdmfrom sklearn.metrics import f1_score, accuracy_score# 定义损失函数和优化器# 这里包含了 PyTorch 的 19 种损失函数 https://blog.csdn.net/qq_35988224/article/details/112911110criterion = torch.nn.CrossEntropyLoss()optimizer = torch.optim.Adam(model.parameters())# 计算 F1 值和 准确率def evaluate(loader, model): preds = [] targets = [] loop = tqdm(loader, total=len(loader), leave=True) for images, labels in loop: images, labels = images.to(device), labels.to(device) with torch.no_grad(): outputs = model(images) _, predicted = torch.max(outputs, 1) preds.extend(predicted.cpu().numpy()) targets.extend(labels.cpu().numpy()) # Update the progress bar loop.set_description(&quot;Evaluating&quot;) return f1_score(targets, preds), accuracy_score(targets, preds)# 训练循环best_f1 = 0.0loss_values = []num_epochs = 10 # 定义训练的轮次for epoch in range(num_epochs): model.train() # 将模型设置为训练模式 loop = tqdm(train_loader, total=len(train_loader), leave=True) print(loop) for images, labels in loop: images, labels = images.to(device), labels.to(device) # 前向推理 outputs = model(images) loss = criterion(outputs, labels) # 反向传播及优化 # 在用 PyTorch训练模型时, 通常会在遍历 Epochs 的过程中依次用到 # optimizer.zero_grad() : 先将梯度归零 # loss.backward() : 反向传播计算得到每个参数的梯度值 # optimizer.step() : 通过梯度下降执行一步参数更新 # 对于这三个函数, 这篇博客写的很好 : https://blog.csdn.net/PanYHHH/article/details/107361827 # 可以简单阅读一遍 optimizer.zero_grad() loss.backward() optimizer.step() # 保存该批次的损失 loss_values.append(loss.item()) # 更新进度条 loop.set_description(f&quot;Epoch [{epoch + 1}/{num_epochs}]&quot;) loop.set_postfix(loss=loss.item()) # 在每轮之后验证模型 model.eval() # 将模型设置为推理模式, 此时模型中的参数不会进行更新, 即完全用于推理/验证 f1_value, accuracy = evaluate(valid_loader, model) print(f'F1 score: {f1_value:.4f}, Accuracy: {accuracy:.4f}') # 保存 F1 值最高的模型 if f1_value &gt; best_f1: best_f1 = f1_value # 这里和上面 Markdown 的保存方式不同, model.state_dict(), 表示模型的参数, 简单来说呢我们仅仅保存了模型的参数, 但是我们并没有保存模型的结构 # 上面 Markdown 的保存方式是即保存了整个模型的结构, 也保存了模型的参数 torch.save(model.state_dict(), 'best_model.pth')print('训练结束') 当然我们也可以使用绘图函数，来展示过程中的相关数据。 12345678910import matplotlib.pyplot as pltplt.figure(figsize=(12, 8))plt.plot(loss_values, label='Train Loss')plt.title('Loss values over epochs')plt.xlabel('Epochs')plt.ylabel('Loss')plt.legend()plt.grid(True)plt.show() 推理模型 很高兴, 如果你到这一步, 你的水平肯定已经有了质的飞跃, 这里已经是最后一步了, 结束这个部分, 你就要开始自己的探索之路了 推理模型很简单, 我在上面说过, 构造模型时指定什么输入 , 推理的时候就要指定什么输入, 这里就是对应的部分了 1234567891011121314151617181920212223242526272829303132from torchvision.transforms import ToTensor, Resize, Normalize# predict_by_file 表示推理一个文件, 我们需要传入文件路径以及模型def predict_by_file(file_path, model): # image = Image.open(file_path).convert('RGB') # 这里的 transform 有与没有都无所谓, 纯看心情 transform = transforms.Compose([ Resize((256, 256)), ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), ]) image = transform(image) # 这里和上面一样, 表示在最外面加一层括号, 使 [3, 256, 256] 变为 [1, 3, 256, 256] image = image.unsqueeze(0).to(device) model.eval() with torch.no_grad(): outputs = model(image) # 模型推理 # torch.max(...) # input (Tensor) – 输入张量 # dim (int) – 指定的维度 _, predicted = torch.max(outputs, 1) # 返回指定维度的最大值, 其实这里只有一维 print(outputs) # tensor([[0.7360, 0.2668]], device='cuda:0') print(outputs.shape) # torch.Size([1, 2]) return &quot;Fake&quot; if predicted.item() == 0 else &quot;Real&quot;path = './dataset/test/real/test_real_7.jpg'print(predict_by_file(path, model))","link":"/2024/03/20/PyTorch%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/"},{"title":"Git常用指令","text":"Git 常用命令 初始化仓库:git init 查看当前仓库的状态git status 切换分支 切换到已有 branchName 分支git checkout branchName 创建新分支，创建的同时切换到该分支git checkout -b newBranch 查看所在目录的分支git branch -a 拉取请求git pull 上传到远程仓库(GitHub) 在 GitHub 配置 SSH_KEY 查看本地是否具有已存在 ssh_key : ll ~/.ssh 如果不存在则生成 ssh_key : ssh-keygen -t rsa -C &quot;xxx@xxx.com&quot; 如果存在则复制 ssh_key 的内容 : cat ~/.ssh/id_rsa.pub 在 GitHub 上添加公钥 : Settings → SSH and GPG Keys → New SSH Key 验证是否成功 : ssh -T git@github.com 克隆远程仓库 : git clone &lt;SSH_Addr&gt; 添加远程仓库地址:git remote add origin &lt;git_addr&gt; 添加文件 git add &lt;files&gt; 添加注释 git commit -m &quot;f&quot; 推送请求 git push -u origin main","link":"/2024/03/26/Git%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2024/03/17/hello-world/"},{"title":"VSCode C++ 的安装和配置","text":"VSCode C++ 的安装和配置 下载 VSCodeVSCode的安装地址 : https://code.visualstudio.com/ 安装和配置 Remote SSH 连接远程的 Linux 服务器 在 VSCode 安装插件 Remote-SSH 点击 左下角→连接到主机→配置SSH主机→选择要更新的SSH的配置文件(C:\\Users\\UserName\\.ssh\\config) 配置文件123Host 服务器的 IP 地址HostName 服务器的 IP 地址User 用户名 连接远程服务器, 按照要求选择操作系统, 输入用户名和密码等即可(第一次连接会较慢) 配置免密登录 Windows 系统下查看是否具有 ssh-key : cd C:/Users/UserName/.ssh 如果没有 ssh-key 则生成 ssh-key : ssh-keygen -t rsa -b 4096 如果有 ssh-key 则上传至 Windows : scp id_rsa.pub UserName@IPAddr:FilePath 在 Linux 系统下进行签名: cat pubPath &gt;&gt; authorized_keys","link":"/2024/03/27/VSCode-C-%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE/"},{"title":"在 Hadoop 高可用的基础上搭建 HBase 高可用","text":"在 Hadoop 高可用的基础上搭建 HBase 高可用当Hadoop高可用搭建完成后，需要进一步再Hadoop高可用集群上搭建HBase高可用时，过程如下： 前提说明： 我的集群为三台机器，每台机器上都有ZooKeeper，使用用户名和主机名（Username@Hostname）分别如下： 123master@mastermaster@slaver01master@slaver02 首先保证 ZooKeeper 正常部署 1zkServer.sh start 需要保证Hadoop正常部署 12[master@master ~]$ start-dfs.sh[master@slaver01 ~]$ start-yarn.sh 解压HBase 配置环境变量 生效环境变量 修改配置文件 修改 hbase-site.xml 文件 123456789101112131415161718192021222324252627282930313233343536&lt;configuration&gt; &lt;!-- HBase数据在HDFS中的存放的路径 --&gt; &lt;!-- 这里 ns 是 Hadoop 的 nameservice的值, 指向的是一个高可用的通道 --&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://ns/hbase&lt;/value&gt; &lt;/property&gt; &lt;!-- HBase 的运行模式 --&gt; &lt;!-- false是单机模式, 若为 false, HBase 和 ZooKeeper 会运行在同一个 JVM 里面 --&gt; &lt;!-- true是分布式模式 --&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;!-- ZooKeeper的地址 --&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master,slaver01,slaver02&lt;/value&gt; &lt;/property&gt; &lt;!-- ZooKeeper快照的存储位置 --&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/opt/module/zookeeper-3.4.6/data&lt;/value&gt; &lt;/property&gt; &lt;!-- V2.1版本，在伪分布式情况下, 设置为 false --&gt; &lt;!-- 当使用 hdfs 时, 设置为 true --&gt; &lt;property&gt; &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 需要注意的是： 这里使用了ns这个高可用通道，因此需要将Hadoop的 core-site.xml 与 hdfs-site.xml移动到/opt/module/hbase-2.1.0/conf下 修改 regionserver 文件 123masterslaver01slaver02","link":"/2024/05/04/Hadoop2HBase/"},{"title":"Hash","text":"哈希(Hash)[TOC] 哈希的基本概念 哈希（Hash）在我的理解中是一种映射关系，例如，将学生映射到学号上、将口红的颜色映射到一个色号上。 哈希函数（Hash Function）就是将一种你想要查询的关键字，比如说姓名、手机号码、数字或者字符串等，映射成便于查找的东西(一般来说是一个数字)的函数。 一般而言，一个好的哈希函数可以帮我们将我们想要查找的东西，从一个较大集合映射到一个较小集合，然后我们可以将这个较小集合中的信息存储下来，例如存入一个数组，这个用于存储较小集合的数组就称之为哈希表。 一张格式如下的表： 学号 姓名 0001 张三 0002 李四 0003 王五 0004 赵六 … … 这张表就可以理解为一个姓名和学号的哈希表，我们通过学号就可以获得学号对应的人的姓名，即：学号[0001] -&gt; &quot;张三&quot;，反映到代码中，可以理解为一个一维数组通过下标直接访问。 而在一些加密工作中，可能需要将要简单的组合复杂化，比如密码组合，这时会有一种类似反向哈希（加密）的过程。 比较常见的哈希函数的例子：$$H(x) = x ; mod ; 11$$ 这个函数可以让我们将任意的整数映射到 0 ~ 10 的范围中 哈希的基本操作 定义哈希函数 1234567const int modnum = 11;int hashTable[modnum];// 定义哈希函数int hash(int x) { return x % modnum;} 在哈希表中插入元素 12345// 在哈希表中插入元素void insert(int x) { int addr = hash(x); hashTable[addr] = x;} 在哈希表中查找元素 12345// 在哈希表中查找元素bool isExist(int x) { int addr = hash(x); return hashTable[addr] == x;} 哈希表中解决冲突的方式不同关键字通过相同哈希函数计算出相同的哈希地址，该种现象称为哈希冲突或哈希碰撞，或者称为哈希冲突。哈希表在存放数据时有可能出现冲突的情况，以上文中的哈希函数为例我们分别向其中插入元素，如下：因为希望哈希表底层数组的容量小于实际要存储的关键字的数量，这就会导致一个问题：冲突的发生是必然的，我们能做的是尽量的降低冲突率。 冲突的解决方式一般有以下两种： 方式 1：顺延一种很好想到的解决方式是将哈希表中插入时产生冲突的元素向后顺延，直到找到一个空位置再进行插入。这种方式称为顺延，也有说法称之为线性探测。此时插入和查找的代码也要发生相应的改变，插入时需要我们需要找到一个空位置来执行插入操作；相对应的查找方式也要做出改变，当我们查询一个数时，也要查询哈希函数对应的位置，并依次比较连续的非空的哈希表中的值： 插入操作 1234567void insert(int x) { int addr = hash(x); while(hashTable[addr] NOT NULL) { // 当哈希表的插入位置不为空 addr = (addr + 1) % modnum; } hashTable[addr] = x;} 查找操作 12345678910void isExist(int x) { int addr = hash(x); while(hashTable[addr] NOT NULL) { // 当哈希表的查询位置不为空(查询一段连续的哈希表) if(hashTable[addr] == x) { // 如果查询到指定元素, 返回 true return true; } addr = (addr + 1) % modnum; } return false;} 可以定义多种解决冲突的顺延函数，即addr = (addr + 1) % modnum，实际使用中可以是每次$+k$，或者$+1^2$，$+2^2$，$+3^2$，…等。 但是这种顺延方式会存在一定的问题：插入时可能会出现多次冲突，当哈希表即将满的时候，插入操作的冲突可能会出现的更多，此时插入和查询操作都会变成一个非常耗时的操作。 方式 2：哈希链表我们可以通过链表的方式，来实现在一个位置放置多个元素的操作。在 C++ 的 STL 库中，我们可以使用 STL 库中提供的 vector 来简单的替代链表。通过这种方式，每次查找元素时，先找到对应的链表头，然后遍历这个位置的整张链表即可。 此时的哈希表的定义、插入操作和查询操作要发生相应的变化： 定义哈希函数 12345678910#include &lt;iostream&gt;#include &lt;vector&gt;const int modnum = 11;vector&lt;int&gt; hashTable[modnum];// 定义哈希函数int hash(int x) { return x % modnum;} 插入操作 1234void insert(int x) { int addr = hash(x); hashTable[addr].push_back(x);} 查询操作 12345678910111213void isExist(int x) { int addr = hash(x); int tableSize = hashTable[addr].size(); // 这里不使用 for(int i = 0; i &lt; hashTable[addr].size(); i++) 的写法, 而是首先计算出 hashTable[addr].size() // 因为 vector 的 size() 是一个比较耗时的操作, 他是通过将 vector 按照一个一个数出来的方式来进行计数的 // 在数据量小的时候可能并不明显, 当数据量大的时候可能就会出现较为严重的耗时问题 for(int i = 0; i &lt; tableSize; i++) { if(hashTable[addr][i] == x) { return true; } } return false;} 但是这种方式还是不能彻底解决我们的问题。对于插入操作来说，时间复杂度可以看作是$O(1)$，对于查询操作来说，时间复杂度和其冲突次数相关联。 哈希函数的设计面对上面的问题，设计好哈希函数才是解决问题的关键。哈希函数在设计的时候，一般要注意几个原则： 设计哈希函数时，我们需要尽可能让查询的值均匀地存储在哈希表中，或者说尽量分散再哈希表中。 在手搓哈希函数时，我们会要求 $H(x) = x ; mod; p$，其中的 $p$ 为素数 哈希函数中的对 $p$ 取摸的操作，会使得哈希值落在 $0 &lt;= value &lt;= p-1$ 的范围内，这个哈希表的长度 $p$，一般被称为哈希表的容量（Capacity）。 插入哈希表的元素总数除以哈希表的容量得到的数，称为负载因子，这里可以用 $\\alpha$ 表示，即：$$\\alpha = ElumNum \\div p$$ 当负载因子$\\alpha$达到一定程度时（一般认为是$0.7\\sim0.8$），则说明再对哈希表继续进行操作，就会面临大量冲突的情况，这时就要考虑增大哈希表的容量以避免出现更多的冲突。 哈希函数的冲突率和负载因子的关系一般如下： 字符串哈希字符串哈希是学习或者工作中经常遇到的一种操作，常用于比较两组字符串的内容等操作。通过比较两个字符串的哈希值就可以完成字符串的比较。$$s = s_1s_2s_3 \\dots s_n\\qquad s_i \\in a, b \\dots z$$ 一个字符串 $s$ 由 $n$ 个字符组成，每个字符 $s_i$ 属于 $a \\sim z$。其哈希函数为：$$\\begin{aligned}H(S)&amp;=(\\sum_{i=1}^{n} c_i × base^{n-i});mod ;p\\&amp;=(c_1 × base ^ {n-1} + c_2 × base ^ {n-2} + \\dots + c_{n-1} × base ^ {1}) ; mod ; p\\&amp;=base^{n-(n-1)}(base\\dots(base(base × c_1 + c_2)));mod ;p\\&amp;=base^{1}(base\\dots(base(base × c_1 + c_2)+c_3)+\\dots + c_n)\\end{aligned};mod ;p$$ 其中 $c_i$ 是一个和 $s_i$ 有关的数字，我们可以将字符映射到数字，例如：$a → 1$、$b → 2$ 等。这里不将 a 映射为 0，因为如果将 a 映射为 0，字符串 a 和 ab 的哈希值是相等的。$base$ 是一个可以自己指定的数字，其值一般是大于字符集中的字符数量（$c_i$的最大值）的素数，这里可以取 31，常见的选择是 9999971。$p$ 是一个素数，常见的选择是 101 或 137。 用代码实现为： 12345678int hash(char s[], int n) { int res = 0; for(int i = 0; i &lt; n; i++) { // 为什么是 res * base, 见上文的描述的公式推导 res = (res * base + (s[i] - 'a' + 1)) % p; } return res;} 当 $base$ 为 31，$p$ 为 101 时。当 $s$ 为 $a$ 时，hash(char s[], int n) 的值为 1。过程可以描述如下： 12[1] res = (0 * base + ('a' - 'a' + 1)) % p&gt;&gt;&gt; res = 1 当 $s$ 为 $ab$ 时，hash(char s[], int n) 的值为 1。过程可以描述如下： 1234[1] res = (0 * base + ('a' - 'a' + 1)) % p&gt;&gt;&gt; res = 1[2] res = (1 * base + ('b' - 'a' + 1)) % p&gt;&gt;&gt; res = 33","link":"/2024/05/05/Hash/"},{"title":"栈(Stack)","text":"栈(Stack)栈的基本概念 栈是一种 先进后出(First in Last Out, FILO) 的数据结构，其类似于我们生活中的衣娄，衣服只能从最顶部放入，也只能从最顶部拿出，要想拿出中间的某件衣服，就需要将顶部的衣服全部拿出，再进行后续的操作。 衣娄对应到栈上，就是以下的概念： 栈(Stack) 是一种类似于衣娄的数据结构，我们可以向其内部存入或者取出数据 栈按照 先进后出 的原则存储数据，每次新进入的数据都会被放在最上面，越先进入的越靠下，越后进入的数据越靠上。 我们只能对最上面的数据进行操作 栈的两大元素：栈的大小和栈顶指针Top（该指针指向栈最顶部的位置） 栈的基本操作 新建栈(题目简单时可以用数组模拟栈) 插入数据 删除栈顶数据 查询栈顶数据 清空栈","link":"/2024/05/04/Stack/"},{"title":"复习数据结构&#x2F;算法清单","text":"复习数据结构清单有日期则表示在该日期已经复习完毕，或者表示复习后的最新一次更新 数据结构 链接 备用链接(Backup Link) 日期 栈(Stack) - - - 队列(Queue) - - - 链表(Link List) - - - 二叉树(Binary Tree) - - - 哈希(Hash) - - - 算法复习清单 算法 链接 备用链接(Backup Link) 日期","link":"/2024/05/04/ReviewAlgorithm/"}],"tags":[{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"软件源","slug":"软件源","link":"/tags/%E8%BD%AF%E4%BB%B6%E6%BA%90/"},{"name":"开发工具","slug":"开发工具","link":"/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"Axure RP 9","slug":"Axure-RP-9","link":"/tags/Axure-RP-9/"},{"name":"闲聊","slug":"闲聊","link":"/tags/%E9%97%B2%E8%81%8A/"},{"name":"计划","slug":"计划","link":"/tags/%E8%AE%A1%E5%88%92/"},{"name":"深度学习","slug":"深度学习","link":"/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"机器学习","slug":"机器学习","link":"/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"PyTorch","slug":"PyTorch","link":"/tags/PyTorch/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"VSCode","slug":"VSCode","link":"/tags/VSCode/"},{"name":"大数据技术","slug":"大数据技术","link":"/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"},{"name":"Hadoop","slug":"Hadoop","link":"/tags/Hadoop/"},{"name":"HBase","slug":"HBase","link":"/tags/HBase/"},{"name":"ZooKeeper","slug":"ZooKeeper","link":"/tags/ZooKeeper/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"数据结构","slug":"数据结构","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"categories":[{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"开发工具","slug":"开发工具","link":"/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"},{"name":"闲聊","slug":"闲聊","link":"/categories/%E9%97%B2%E8%81%8A/"},{"name":"软件源","slug":"Linux/软件源","link":"/categories/Linux/%E8%BD%AF%E4%BB%B6%E6%BA%90/"},{"name":"Axure RP 9","slug":"开发工具/Axure-RP-9","link":"/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/Axure-RP-9/"},{"name":"计划","slug":"闲聊/计划","link":"/categories/%E9%97%B2%E8%81%8A/%E8%AE%A1%E5%88%92/"},{"name":"深度学习","slug":"深度学习","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"Git","slug":"开发工具/Git","link":"/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/Git/"},{"name":"VSCode","slug":"开发工具/VSCode","link":"/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/VSCode/"},{"name":"PyTorch","slug":"深度学习/PyTorch","link":"/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/PyTorch/"},{"name":"大数据技术","slug":"大数据技术","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"},{"name":"HBase","slug":"大数据技术/HBase","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/HBase/"},{"name":"数据结构&#x2F;算法","slug":"数据结构-算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/"},{"name":"哈希(Hash)","slug":"数据结构-算法/哈希-Hash","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/%E5%93%88%E5%B8%8C-Hash/"},{"name":"栈(Stack)","slug":"数据结构-算法/栈-Stack","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/%E6%A0%88-Stack/"}],"pages":[]}