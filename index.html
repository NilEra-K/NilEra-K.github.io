<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><meta name="theme-color" content="#123456"><meta name="generator" content="Hexo 4.2.0"><title>Hello, NilEra :-)</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hello, NilEra :-)"><meta name="msapplication-TileImage" content="/img/StarLogo.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hello, NilEra :-)"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="努力做自己喜欢的事"><meta property="og:type" content="blog"><meta property="og:title" content="Hello, NilEra :-)"><meta property="og:url" content="https://hello-nilera.com/"><meta property="og:site_name" content="Hello, NilEra :-)"><meta property="og:description" content="努力做自己喜欢的事"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://hello-nilera.com/img/og_image.png"><meta property="article:author" content="NilEra"><meta property="article:tag" content="Hello NilEra"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://hello-nilera.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hello-nilera.com"},"headline":"Hello, NilEra :-)","image":["https://hello-nilera.com/img/og_image.png"],"author":{"@type":"Person","name":"NilEra"},"publisher":{"@type":"Organization","name":"Hello, NilEra :-)","logo":{"@type":"ImageObject","url":"https://hello-nilera.com/img/StarLogo.svg"}},"description":"努力做自己喜欢的事"}</script><link rel="icon" href="/img/StarLogo.svg"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/6.0.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/11.7.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?249654dcf9a3bf70708fdfc6e2b1ec2b";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><meta name="msvalidate.01" content="F6BD78C6BD0096D2218CF88334111125"><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.loli.net/ajax/libs/pace/1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/StarLogo.svg" alt="Hello, NilEra :-)" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item is-active" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">目录</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a><a class="navbar-item" href="/me">我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/NilEra-K"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-09-05T07:07:36.000Z" title="2024/9/5 15:07:36">2024-09-05</time>发表</span><span class="level-item"><time dateTime="2024-09-05T13:13:59.683Z" title="2024/9/5 21:13:59">2024-09-05</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span> / </span><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Stable-Diffusion/">Stable_Diffusion</a></span><span class="level-item">几秒读完 (大约55个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/09/05/How2Use-Stable-Diffusion/">How2Use_Stable_Diffusion</a></p><div class="content"><h1 id="🤔-How-To-Use-Stable-Diffusion"><a href="#🤔-How-To-Use-Stable-Diffusion" class="headerlink" title="🤔 How To Use Stable Diffusion"></a>🤔 How To Use Stable Diffusion</h1><p>Extension：</p>
<p>ChatGPT-4V</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">chmod</span> u+x install_linux_mac.sh</span><br><span class="line">./install_linux_mac.sh</span><br></pre></td></tr></table></figure>

<p>出现错误：</p>
<p>ImportError: Using SOCKS proxy, but the ‘socksio’ package is not installed. Make sure to install httpx using <code>pip install httpx[socks]</code>.</p>
<p>unset all_proxy &amp;&amp; unset ALL_PROXY</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-08-22T09:58:38.000Z" title="2024/8/22 17:58:38">2024-08-22</time>发表</span><span class="level-item"><time dateTime="2024-08-22T12:08:59.048Z" title="2024/8/22 20:08:59">2024-08-22</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span> / </span><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/">网络架构</a><span> / </span><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/Kolmogorov-Arnold-Networks/">Kolmogorov-Arnold Networks</a></span><span class="level-item">2 分钟读完 (大约332个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/08/22/Kolmogorov-Arnold-Networks/">Kolmogorov-Arnold Networks</a></p><div class="content"><h2 id="Kolmogorov-Arnold-Networks-KAN"><a href="#Kolmogorov-Arnold-Networks-KAN" class="headerlink" title="Kolmogorov-Arnold Networks (KAN)"></a>Kolmogorov-Arnold Networks (KAN)</h2><blockquote>
<p><strong>What <code>KAN</code> I Say ? <code>MLP</code> OUT !</strong></p>
</blockquote>
<p>Kolmogorov-Arnold Networks(KAN)</p>
<p>[TOC]</p>
<p><code>KAN</code> 源码中的核心组件：</p>
<table>
<thead>
<tr>
<th>核心代码</th>
<th>主要内容</th>
</tr>
</thead>
<tbody><tr>
<td><code>KAN.py</code></td>
<td>主要的文件，包含定义 <code>KAN</code> 模型的主要类和函数，定义了 <code>KAN</code> 模型，它由多个 <code>KANLayer</code> 和 <code>Symbolic_KANLayer</code>  组成，包含前向传播、模式设置、符号激活函数的固定和建议、模型训练、剪枝以及可视化等功能。</td>
</tr>
<tr>
<td><code>KANLayer.py</code></td>
<td>定义 <code>KAN</code> 模型中使用的自定义层，包括模型的核心组件，如特殊的激活函数或其他处理层，是构成 <code>KAN</code> 的基础。</td>
</tr>
<tr>
<td><code>LBFGS.py</code></td>
<td>包含使用 <code>KAN</code> 训练的 <code>L-BFGS</code> 优化器的实现，用于在训练过程中对 <code>KAN</code> 的参数进行优化。</td>
</tr>
<tr>
<td><code>Symbolic_KANLayer.py</code></td>
<td>实现了一种特殊的 <code>KAN</code> 层，用于处理符号计算或增强模型解释性，用符号函数（如正弦）来代替传统的数值激活函数。以便深入分析和解释。</td>
</tr>
<tr>
<td><code>spline.py</code></td>
<td>包含实现样条函数的代码，提供一系列函数，用于处理 B 样条曲线。包括：计算 B 样条基函数、从系数生成样条曲线，以及从样条曲线估计系数等。</td>
</tr>
</tbody></table>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-08-18T02:35:39.000Z" title="2024/8/18 10:35:39">2024-08-18</time>发表</span><span class="level-item"><time dateTime="2024-08-18T02:35:39.334Z" title="2024/8/18 10:35:39">2024-08-18</time>更新</span><span class="level-item">几秒读完 (大约0个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/08/18/Create-AN-Environment-of-Kaggle/">Create_AN_Environment_of_Kaggle</a></p><div class="content"></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-08-17T01:24:42.000Z" title="2024/8/17 09:24:42">2024-08-17</time>发表</span><span class="level-item"><time dateTime="2024-09-03T14:02:31.676Z" title="2024/9/3 22:02:31">2024-09-03</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span> / </span><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Kaggle/">Kaggle</a></span><span class="level-item">13 分钟读完 (大约1953个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/08/17/RSNA-2024/">RSNA-2024</a></p><div class="content"><h2 id="RSNA-2024-Lumbar-Spine-Degenerative-Classification-腰椎退行性分类"><a href="#RSNA-2024-Lumbar-Spine-Degenerative-Classification-腰椎退行性分类" class="headerlink" title="RSNA 2024 Lumbar Spine Degenerative Classification 腰椎退行性分类"></a>RSNA 2024 Lumbar Spine Degenerative Classification 腰椎退行性分类</h2><p>Classify lumbar spine degenerative conditions：对腰椎退行性疾病进行分类</p>
<p>[TOC]</p>
<h3 id="Overview-概述"><a href="#Overview-概述" class="headerlink" title="Overview 概述"></a>Overview 概述</h3><p><em>The goal of this competition is to create models that can be used to aid in the detection and classification of degenerative spine conditions using lumbar spine MR images. Competitors will develop models that simulate a radiologist’s performance in diagnosing spine conditions.</em></p>
<p>本次竞赛的目标是创建可用于帮助使用腰椎 MR 图像检测和分类脊柱退行性疾病的模型。参赛者将开发模型来模拟放射科医生诊断脊柱疾病的表现。</p>
<h4 id="Description-描述"><a href="#Description-描述" class="headerlink" title="Description 描述"></a>Description 描述</h4><p><em>Low back pain is the leading cause of disability worldwide, according to the World Health Organization, affecting 619 million people in 2020. Most people experience low back pain at some point in their lives, with the frequency increasing with age. Pain and restricted mobility are often symptoms of spondylosis, a set of degenerative spine conditions including degeneration of intervertebral discs and subsequent narrowing of the spinal canal (spinal stenosis), subarticular recesses, or neural foramen with associated compression or irritations of the nerves in the low back.</em></p>
<p>根据世界卫生组织的数据，腰痛是全球范围内导致残疾的主要原因，到 2020 年，腰痛将影响 6.19 亿人。大多数人在一生中的某个阶段都会经历腰痛，且频率随着年龄的增长而增加。疼痛和活动受限通常是脊椎病的症状，这是一组退行性脊柱疾病，包括椎间盘退变和随后的椎管变窄（椎管狭窄）、关节下隐窝或神经孔，并伴有下肢神经受压或刺激。</p>
<p><em>Magnetic resonance imaging (MRI) provides a detailed view of the lumbar spine vertebra, discs and nerves, enabling radiologists to assess the presence and severity of these conditions. Proper diagnosis and grading of these conditions help guide treatment and potential surgery to help alleviate back pain and improve overall health and quality of life for patients.</em></p>
<p>磁共振成像 (MRI) 提供腰椎、椎间盘和神经的详细视图，使放射科医生能够评估这些病症的存在和严重程度。对这些病症的正确诊断和分级有助于指导治疗和潜在的手术，以帮助减轻背痛并改善患者的整体健康和生活质量。</p>
<p><em>RSNA has teamed with the <a target="_blank" rel="noopener" href="https://www.asnr.org/">American Society of Neuroradiology (ASNR)</a> to conduct this competition exploring whether artificial intelligence can be used to aid in the detection and classification of degenerative spine conditions using lumbar spine MR images.</em></p>
<p>RSNA 与<a target="_blank" rel="noopener" href="https://www.asnr.org/">美国神经放射学会 (ASNR)</a>合作举办了本次竞赛，探讨人工智能是否可以利用腰椎 MR 图像来帮助检测和分类脊柱退行性疾病。</p>
<p><em>The challenge will focus on the classification of five lumbar spine degenerative conditions: Left Neural Foraminal Narrowing, Right Neural Foraminal Narrowing, Left Subarticular Stenosis, Right Subarticular Stenosis, and Spinal Canal Stenosis. For each imaging study in the dataset, we’ve provided severity scores (Normal&#x2F;Mild, Moderate, or Severe) for each of the five conditions across the intervertebral disc levels L1&#x2F;L2, L2&#x2F;L3, L3&#x2F;L4, L4&#x2F;L5, and L5&#x2F;S1.</em></p>
<p>挑战将集中于五种腰椎退行性疾病的分类：左神经椎间孔狭窄、右神经椎间孔狭窄、左关节下狭窄、右关节下狭窄和椎管狭窄。对于数据集中的每项影像学研究，我们为椎间盘 L1&#x2F;L2、L2&#x2F;L3、L3&#x2F;L4、L4&#x2F;L5 级别的五种情况中的每一种提供了严重性评分（正常&#x2F;轻度、中度或严重）和 L5&#x2F;S1。</p>
<p><em>To create the ground truth dataset, the RSNA challenge planning task force collected imaging data sourced from eight sites on five continents. This multi-institutional, expertly curated dataset promises to improve standardized classification of degenerative lumbar spine conditions and enable development of tools to automate accurate and rapid disease classification.</em></p>
<p>为了创建实况数据集，RSNA 挑战计划工作组收集了来自五大洲八个站点的成像数据。这个多机构、专业策划的数据集有望改善退行性腰椎疾病的标准化分类，并支持开发自动化准确、快速的疾病分类工具。</p>
<p><em>Challenge winners will be recognized at an event during the RSNA 2024 annual meeting. For more information on the challenge, contact RSNA Informatics staff at <a href="mailto:informatics@rsna.org">informatics@rsna.org</a>.</em></p>
<p>挑战赛获胜者将在 RSNA 2024 年年会期间的活动中获得表彰。有关挑战的更多信息，请联系 RSNA 信息学工作人员： <a href="mailto:informatics@rsna.org">informatics@rsna.org</a> 。</p>
<h4 id="Evaluation-评估"><a href="#Evaluation-评估" class="headerlink" title="Evaluation 评估"></a>Evaluation 评估</h4><p><em>Submissions are evaluated using the average of sample weighted log losses and an <code>any_severe_spinal</code> prediction generated by the metric. The <a target="_blank" rel="noopener" href="https://www.kaggle.com/code/metric/rsna-lumbar-metric-71549">metric notebook can be found here</a>.</em></p>
<p>使用样本加权对数损失的平均值和由该指标生成的<code>any_severe_spinal</code>预测来评估提交的结果。<a target="_blank" rel="noopener" href="https://www.kaggle.com/code/metric/rsna-lumbar-metric-71549">公制笔记本可以在这里找到</a>。</p>
<p><em>The sample weights are as follows:</em></p>
<p>样本权重如下：</p>
<ul>
<li>1 for normal&#x2F;mild. 1 为正常&#x2F;轻度。</li>
<li>2 for moderate. 2为中等。</li>
<li>4 for severe. 4为严重。</li>
</ul>
<p><em>For each row ID in the test set, you must predict a probability for each of the different severity levels. The file should contain a header and have the following format:</em></p>
<p>对于测试集中的每个行 ID，您必须预测每个不同严重性级别的概率。该文件应包含标头并具有以下格式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">row_id,normal_mild,moderate,severe</span><br><span class="line">123456_left_neural_foraminal_narrowing_l1_l2,0.333,0.333,0.333</span><br><span class="line">123456_left_neural_foraminal_narrowing_l2_l3,0.333,0.333,0.333</span><br><span class="line">123456_left_neural_foraminal_narrowing_l3_l4,0.333,0.333,0.333</span><br><span class="line">etc.</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>row_id</th>
<th>normal_mild</th>
<th>moderate</th>
<th>severe</th>
</tr>
</thead>
<tbody><tr>
<td>123456_left_neural_foraminal_narrowing_l1_l2</td>
<td>0.333</td>
<td>0.333</td>
<td>0.333</td>
</tr>
<tr>
<td>123456_left_neural_foraminal_narrowing_l2_l3</td>
<td>0.333</td>
<td>0.333</td>
<td>0.333</td>
</tr>
<tr>
<td>123456_left_neural_foraminal_narrowing_l3_l4</td>
<td>0.333</td>
<td>0.333</td>
<td>0.333</td>
</tr>
<tr>
<td>etc.</td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p><em>In rare cases the lowest vertebrae aren’t visible in the imagery. You still need to make predictions (nulls will cause errors), but those rows will not be scored.</em></p>
<p>在极少数情况下，图像中看不到最低的椎骨。您仍然需要进行预测（空值会导致错误），但这些行不会被评分。</p>
<p><em>For this competition, the</em> <code>any_severe_scalar</code> <em>has been set to</em> <code>1.0</code>.</p>
<p>对于本次比赛，<code>any_severe_scalar</code>已设置为<code>1.0</code> 。</p>
<h3 id="Dataset-Description-数据集描述"><a href="#Dataset-Description-数据集描述" class="headerlink" title="Dataset Description 数据集描述"></a>Dataset Description 数据集描述</h3><p>The goal of this competition is to identify medical conditions affecting the lumbar spine in MRI scans.<br>本次比赛的目标是通过 MRI 扫描识别影响腰椎的医疗状况。</p>
<p>This competition uses a hidden test. When your submitted notebook is scored, the actual test data (including a full length sample submission) will be made available to your notebook.<br>本次比赛采用隐藏测试方式。当您提交的笔记本电脑被评分时，实际的测试数据（包括完整长度的样本提交）将提供给您的笔记本电脑。</p>
<h4 id="Files-文件"><a href="#Files-文件" class="headerlink" title="Files 文件"></a>Files 文件</h4><p><strong>train.csv</strong> <em>Labels for the train set</em>. 训练集的标签。</p>
<ul>
<li><code>study_id</code> - <em>The study ID. Each study may include multiple series of images.</em><br><code>study_id</code> - 研究 ID，每个研究可能包括多个系列的图像。</li>
<li><code>[condition]_[level]</code> - <em>The target labels, such as</em> <code>spinal_canal_stenosis_l1_l2</code> <em>, with the severity levels of</em> <code>Normal/Mild</code><em>,</em> <code>Moderate</code> <em>, or</em> <code>Severe</code> <em>. Some entries have incomplete labels.</em><br><code>[condition]_[level]</code> - 目标标签，例如<code>spinal_canal_stenosis_l1_l2</code> ，严重程度级别为 <code>Normal/Mild</code> 、 <code>Moderate</code> 或 <code>Severe</code>。有些条目的标签不完整。</li>
</ul>
<p><strong>train_label_coordinates.csv<br>训练标签坐标.csv</strong></p>
<ul>
<li><code>study_id</code></li>
<li><code>series_id</code> - The imagery series ID.<br><code>series_id</code> - 图像系列 ID。</li>
<li><code>instance_number</code> - The image’s order number within the 3D stack.<br><code>instance_number</code> - 图像在 3D 堆栈中的顺序号。</li>
<li><code>condition</code> - There are three core conditions: spinal canal stenosis, neural_foraminal_narrowing, and subarticular_stenosis. The latter two are considered for each side of the spine.<br><code>condition</code> - 共有三种核心病症：椎管狭窄、神经椎间孔狭窄和关节下狭窄。脊柱的每一侧都考虑后两者。</li>
<li><code>level</code> - The relevant vertebrae, such as <code>l3_l4</code><br><code>level</code> - 相关椎骨，例如<code>l3_l4</code></li>
<li><code>[x/y]</code> - The x&#x2F;y coordinates for the center of the area that defined the label.<br><code>[x/y]</code> - 定义标签的区域中心的 x&#x2F;y 坐标。</li>
</ul>
<p><strong>sample_submission.csv 样本提交.csv</strong></p>
<ul>
<li><code>row_id</code> - A slug of the study ID, condition, and level such as <code>12345_spinal_canal_stenosis_l3_l4</code>.<br><code>row_id</code> - 研究 ID、条件和级别的 slug，例如<code>12345_spinal_canal_stenosis_l3_l4</code> 。</li>
<li><code>[normal_mild/moderate/severe]</code> - The three prediction columns.<br><code>[normal_mild/moderate/severe]</code> - 三个预测列。</li>
</ul>
<p><strong>[train&#x2F;test]_images&#x2F;[study_id]&#x2F;[series_id]&#x2F;[instance_number].dcm</strong> The imagery data.图像数据。</p>
<p><strong>[train&#x2F;test]_series_descriptions.csv</strong></p>
<ul>
<li><p><code>study_id</code></p>
</li>
<li><p><code>series_id</code></p>
</li>
<li><p><code>series_description</code> The scan’s orientation.<br><code>series_description</code> 扫描方向。</p>
</li>
</ul>
<h3 id="方案说明"><a href="#方案说明" class="headerlink" title="方案说明"></a>方案说明</h3><p>Transformer + KAN 6.09 结果很不好</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-08-15T09:21:54.000Z" title="2024/8/15 17:21:54">2024-08-15</time>发表</span><span class="level-item"><time dateTime="2024-08-17T02:10:35.432Z" title="2024/8/17 10:10:35">2024-08-17</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/CppDev/">CppDev</a><span> / </span><a class="link-muted" href="/categories/CppDev/%E8%AF%AD%E6%B3%95%E7%82%B9/">语法点</a><span> / </span><a class="link-muted" href="/categories/CppDev/%E8%AF%AD%E6%B3%95%E7%82%B9/%E8%99%9A%E5%87%BD%E6%95%B0/">虚函数</a></span><span class="level-item">2 分钟读完 (大约276个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/08/15/Virtual-Destructor-IN-Cpp/">Virtual_Destructor_IN_Cpp</a></p><div class="content"><h2 id="C-中虚析构函数的使用"><a href="#C-中虚析构函数的使用" class="headerlink" title="C++ 中虚析构函数的使用"></a>C++ 中虚析构函数的使用</h2><p>析构函数是为了在对象不被使用之后释放它的资源，虚函数是为了实现多态。那么把析构函数声明为 <code>vitual</code> 有什么作用呢？<br>直接的讲，<code>C++</code> 中基类采用<code>virtual</code>虚析构函数是为了防止内存泄漏。具体地说，如果派生类中申请了内存空间，并在其析构函数中对这些内存空间进行释放。假设基类中采用的是非虚析构函数，当删除基类指针指向的派生类对象时就不会触发动态绑定，因而只会调用基类的析构函数，而不会调用派生类的析构函数。那么在这种情况下，派生类中申请的空间就得不到释放从而产生内存泄漏。所以，为了防止这种情况的发生，<code>C++</code> 中基类的析构函数应采用<code>virtual</code>虚析构函数</p>
<p>参考文献：</p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_34673519/article/details/101429799">https://blog.csdn.net/qq_34673519/article/details/101429799</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-08-13T12:19:01.000Z" title="2024/8/13 20:19:01">2024-08-13</time>发表</span><span class="level-item"><time dateTime="2024-09-03T14:00:56.494Z" title="2024/9/3 22:00:56">2024-09-03</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span> / </span><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LLMs/">LLMs</a></span><span class="level-item">6 分钟读完 (大约862个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/08/13/Deploy-LLMs-ON-Linux/">Deploy_LLMs_ON_Linux</a></p><div class="content"><h2 id="如何在-Linux-服务器上搭建本地LLMs-🤔"><a href="#如何在-Linux-服务器上搭建本地LLMs-🤔" class="headerlink" title="如何在 Linux 服务器上搭建本地LLMs 🤔"></a>如何在 Linux 服务器上搭建本地LLMs 🤔</h2><p>如何在 <code>Linux</code> 服务器上部署大语言模型，以 <code>qwen1_5-32b-chat-q8_k_0</code> 为例。服务器使用显卡 <code>A4000</code>，预算：$5950$ 元。</p>
<h3 id="搭建-qwen1-5-32b-chat-q8-k-0"><a href="#搭建-qwen1-5-32b-chat-q8-k-0" class="headerlink" title="搭建 qwen1_5-32b-chat-q8_k_0"></a>搭建 <code>qwen1_5-32b-chat-q8_k_0</code></h3><ol>
<li><p>下载 🤗<code>Hugging Face</code> 库，这个库主要是用于下载模型使用。当然为了保证速度，我们可以使用 <code>wget</code> 命令替代他。如果你决定使用 <code>wget</code> 命令，你可以选择跳过这一步，具体的使用方式在第五步呈现。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  ~ pip install huggingface_hub</span><br></pre></td></tr></table></figure>

<p>或者是直接下载 <code>modelscope</code> 库，使用 <code>modelscope</code> 下载模型（⭐推荐）。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  ~ pip install modelscope</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建一个 <code>LocalGit</code> 文件夹，并进入该文件夹</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  ~ <span class="built_in">mkdir</span> LocalGit</span><br><span class="line">(base) ➜  ~ <span class="built_in">cd</span> LocalGit</span><br><span class="line">(base) ➜  LocalGit </span><br></pre></td></tr></table></figure>
</li>
<li><p>克隆 <code>llama.cpp</code> 的仓库</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  LocalGit git <span class="built_in">clone</span> https://github.com/ggerganov/llama.cpp</span><br><span class="line">(base) ➜  LocalGit <span class="built_in">cd</span> llama.cpp</span><br><span class="line">(base) ➜  llama.cpp git:(master)</span><br></pre></td></tr></table></figure>
</li>
<li><p>在有 <code>GPU</code> 的环境下编译 <code>llama.cpp</code></p>
<p><strong>前置条件：</strong>安装 <code>nvcc</code> + <code>cmake</code></p>
<p>执行代码进行编译：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  llama.cpp git:(master) make LLAMA_CUBLAS=1 LLAMA_CUDA_NVCC=/usr/local/cuda/bin/nvcc</span><br></pre></td></tr></table></figure>

<p>如果出现错误：<code>(base) ➜  llama.cpp git:(master) make LLAMA_CUBLAS=1 LLAMA_CUDA_NVCC=/usr/local/cuda/bin/nvcc Makefile:76: *** LLAMA_CUBLAS is removed. Use GGML_CUDA instead..  Stop.</code></p>
<p>修改代码如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  llama.cpp git:(master) make GGML_CUDA=1 LLAMA_CUDA_NVCC=/usr/local/cuda/bin/nvcc</span><br></pre></td></tr></table></figure>

<p>为了加快编译速度，我们可以尝试以下命令添加参数 <code>j</code>，<code>j</code> 后面的数字表示同时编译的线程数（可根据 <code>CPU</code> 核数决定），实测能缩短约 $1&#x2F;3$ 的时间：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  llama.cpp git:(master) make -j6 GGML_CUDA=1 LLAMA_CUDA_NVCC=/usr/local/cuda/bin/nvcc</span><br></pre></td></tr></table></figure>
</li>
<li><p>下载相应的模型</p>
<p>① 使用 <code>Hugging Face</code> 下载相应模型，实测服务器网速在 <code>3M~6M</code> 左右，具体方式如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  ~ huggingface-cli download Qwen/Qwen1.5-32B-Chat-GGUF qwen1_5-32b-chat-q8_0.gguf --local-dir . --local-dir-use-symlinks False</span><br></pre></td></tr></table></figure>

<p>② 使用 <code>wget</code> 下载 <code>modelscope</code> 的模型文件，实测网速在 <code>10M~22M</code> 左右，这需要你先获取到模型的下载链接，具体方式如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  ~ wget https://www.modelscope.cn/models/qwen/Qwen1.5-32B-Chat-GGUF/resolve/master/qwen1_5-32b-chat-q8_0.gguf</span><br></pre></td></tr></table></figure>

<p>③ 直接使用 <code>modelscope</code> 库下载模型，实测网速在 <code>18M~65M</code> 左右，具体方式如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  ~ <span class="built_in">cd</span> LocalGit </span><br><span class="line">(base) ➜  LocalGit <span class="built_in">mkdir</span> models</span><br><span class="line">(base) ➜  LocalGit <span class="built_in">cd</span> models</span><br><span class="line">(base) ➜  models modelscope download --model=qwen/Qwen2-7B-Instruct-GGUF --local_dir . qwen2-7b-instruct-q8_0.gguf</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用 <code>llama.cpp</code> 的相关命令进行操作</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  llama.cpp git:(master) ./main -m ../models/qwen1_5-32b-chat-q8_0.gguf -n 512 --color -i -cml -f prompts/chat-with-qwen.txt</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  llama.cpp git:(master) ./llama-server -m ../models/qwen1_5-32b-chat-q8_0.gguf -ngl 80 -fa</span><br></pre></td></tr></table></figure>

<p>如果是 <code>Qwen2-7B-Instruct-GGUF</code>，可以参考官方文档：<a target="_blank" rel="noopener" href="https://www.modelscope.cn/models/qwen/qwen2-7b-instruct-gguf">Qwen2-7B-Instruct-GGUF · 模型库 — Qwen2-7B-Instruct-GGUF · 模型库 (modelscope.cn)</a></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(base) ➜  llama.cpp git:(master) ./llama-server -m qwen2-7b-instruct-q8_0.gguf -ngl 29 -fa</span><br></pre></td></tr></table></figure>
</li>
<li><p>兼容 <code>OpenAI API</code>，使用 <code>Python</code> 代码测试</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">import openai</span><br><span class="line"></span><br><span class="line">client = openai.OpenAI(</span><br><span class="line">    base_url=<span class="string">&quot;http://localhost:8080/v1&quot;</span>, <span class="comment"># &quot;http://&lt;Your api-server IP&gt;:port&quot;</span></span><br><span class="line">    api_key = <span class="string">&quot;sk-no-key-required&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">completion = client.chat.completions.create(</span><br><span class="line">    model=<span class="string">&quot;qwen&quot;</span>,</span><br><span class="line">    messages=[</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;You are a helpful assistant.&quot;</span>&#125;,</span><br><span class="line">        &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;tell me something about michael jordan&quot;</span>&#125;</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"><span class="built_in">print</span>(completion.choices[0].message.content)</span><br></pre></td></tr></table></figure>
</li>
<li><p>命令启动</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">./llama-cli -m qwen2-7b-instruct-q5_k_m.gguf \</span><br><span class="line">  -n 512 -co -i -<span class="keyword">if</span> -f prompts/chat-with-qwen.txt \</span><br><span class="line">  --in-prefix <span class="string">&quot;&lt;|im_start|&gt;user\n&quot;</span> \</span><br><span class="line">  --in-suffix <span class="string">&quot;&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\n&quot;</span> \</span><br><span class="line">  -ngl 24 -fa</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="拓展补充"><a href="#拓展补充" class="headerlink" title="拓展补充"></a>拓展补充</h3><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/shebao3333/article/details/139428868">Llama.cpp大模型量化简明手册_llamacpp量化-CSDN博客</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-08-12T15:10:23.000Z" title="2024/8/12 23:10:23">2024-08-12</time>发表</span><span class="level-item"><time dateTime="2024-08-13T09:55:49.971Z" title="2024/8/13 17:55:49">2024-08-13</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span> / </span><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LLMs/">LLMs</a></span><span class="level-item">2 分钟读完 (大约226个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/08/12/Windows-Build-llama-cpp/">Windows Build llama.cpp</a></p><div class="content"><h2 id="Windows-平台下构建-llama-cpp"><a href="#Windows-平台下构建-llama-cpp" class="headerlink" title="Windows 平台下构建 llama.cpp"></a>Windows 平台下构建 <code>llama.cpp</code></h2><p>在使用 <code>LM-Studio</code> 时，对于一些参数量不是很大的模型来说，大多数不需要进行模型的合并，如 <code>qwen2-7b</code> 等。这些模型往往只需要下载后加载到 <code>LM-Studio</code> 中即可。</p>
<p>但是对于参数量很大的模型，如 <code>qwen2-72b-instruct</code> 等，因为模型文件较大不利于传输，因此模型开发者可能会使用 <code>llama.cpp</code> 对 <code>GGUF</code> 模型进行拆分，所以这个时候我们在下载模型时就需要进行模型的合并。</p>
<p><code>qwen2-72b-instruct</code> 在 <code>q8</code> 量化给出了两个模型文件，分别是：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">qwen2-72b-instruct-q8_k_m-00001-of-00002.gguf</span><br><span class="line">qwen2-72b-instruct-q8_k_m-00002-of-00002.gguf</span><br></pre></td></tr></table></figure>

<p>为了使用这些分割后的 <code>GGUF</code> 文件，我们可以使用 <code>llama-gguf-split</code> 合并他们</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">llama-gguf-spilt --merge input.gguf output.gguf</span><br></pre></td></tr></table></figure>

</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-08-06T08:52:53.000Z" title="2024/8/6 16:52:53">2024-08-06</time>发表</span><span class="level-item"><time dateTime="2024-08-07T14:36:50.427Z" title="2024/8/7 22:36:50">2024-08-07</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/CppDev/">CppDev</a><span> / </span><a class="link-muted" href="/categories/CppDev/%E8%AF%AD%E6%B3%95%E7%82%B9/">语法点</a><span> / </span><a class="link-muted" href="/categories/CppDev/%E8%AF%AD%E6%B3%95%E7%82%B9/bind/">bind</a></span><span class="level-item">几秒读完 (大约74个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/08/06/CPP-11-functional-bind/">CPP_11 functional bind</a></p><div class="content"><h2 id="C-11-函数适配器-bind"><a href="#C-11-函数适配器-bind" class="headerlink" title="C++ 11 函数适配器 bind"></a>C++ 11 函数适配器 <code>bind</code></h2><p>参考博客：</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/zhoug2020/p/13583307.html">C++11新特性：参数绑定——std::bind - 莫水千流 - 博客园 (cnblogs.com)</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_38410730/article/details/103637778">【C++】C++11的std::function和std::bind用法详解_c++11 新增了 std::function、std::bind-CSDN博客</a></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-08-06T02:54:59.000Z" title="2024/8/6 10:54:59">2024-08-06</time>发表</span><span class="level-item"><time dateTime="2024-08-06T04:02:29.167Z" title="2024/8/6 12:02:29">2024-08-06</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/CppDev/">CppDev</a><span> / </span><a class="link-muted" href="/categories/CppDev/%E8%AF%AD%E6%B3%95%E7%82%B9/">语法点</a><span> / </span><a class="link-muted" href="/categories/CppDev/%E8%AF%AD%E6%B3%95%E7%82%B9/enum-class/">enum class</a></span><span class="level-item">2 分钟读完 (大约372个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/08/06/CPP-11-Enum-Class/">CPP_11 Enum Class</a></p><div class="content"><h2 id="C-11-枚举类-enum-class"><a href="#C-11-枚举类-enum-class" class="headerlink" title="C++ 11 枚举类 enum class"></a>C++ 11 枚举类 <code>enum class</code></h2><p>我们在 <code>C++</code> 中常使用 <code>enum</code> 来给同一类别中的多个值命名，如：给颜色中的 <code>0, 1, 2, 3, ...</code> 值命名，可以用下面的写法：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> <span class="title class_">Color</span> &#123;</span><br><span class="line">    Red,</span><br><span class="line">    Yellow,</span><br><span class="line">    Blue,</span><br><span class="line">    Gray,</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p><code>C++</code> 的 <code>C98</code> 标准称 <code>enum</code> 为<strong>不限范围的枚举型别</strong>。因为 <code>C++</code> 中的枚举量会泄露到包含这个枚举类型的作用域内，在这个作用域内就不能有其他实体取相同的名字。我们可以通过一段代码来演示这一现象：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">Color</span> &#123;</span><br><span class="line">    RED,</span><br><span class="line">    YELLOW,</span><br><span class="line">    BLUE,</span><br><span class="line">    GRAY</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> GRAY = <span class="number">10</span>; </span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; GRAY &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当我们编译时，会出现重定义错误：<code>error: &#39;auto GRAY&#39; redeclared as different kind of entity</code>。</p>
<p>为了解决这一问题，<code>C++ 11</code> 新标准提供了 <strong><code>enum Class</code> 枚举类</strong>。对于上面的代码，我们再一次做出演示：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">enum class</span> <span class="title class_">Color</span> &#123;</span><br><span class="line">    RED,</span><br><span class="line">    YELLOW,</span><br><span class="line">    BLUE,</span><br><span class="line">    GRAY</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">auto</span> GRAY = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(Color::GRAY) &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; GRAY &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>此时，输出 <code>3</code> 和 <code>10</code>。可以看到在全局作用域的 <code>GRAY</code> 被赋值成了 <code>10</code>，而枚举类中的 <code>GRAY</code> 还是 <code>3</code>，且必须使用作用域限定符进行访问。 这里可以看到我使用了一个 <code>static_cast&lt;int&gt; (Color::GRAY)</code> 进行了一个强制类型转换，这是因为 <code>enum</code> 不支持隐式类型转换。如果想要进行转换，则必须使用 <code>static_cast</code> 进行强制类型转换。</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-08-05T02:37:16.000Z" title="2024/8/5 10:37:16">2024-08-05</time>发表</span><span class="level-item"><time dateTime="2024-08-14T10:13:32.001Z" title="2024/8/14 18:13:32">2024-08-14</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span> / </span><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LLMs/">LLMs</a></span><span class="level-item">8 分钟读完 (大约1240个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/08/05/Deploy-LLMs-ON-PC/">Deploy_LLMs_ON_PC</a></p><div class="content"><h2 id="如何搭建运行在本地的-LLMs-🤔"><a href="#如何搭建运行在本地的-LLMs-🤔" class="headerlink" title="如何搭建运行在本地的 LLMs 🤔"></a>如何搭建运行在本地的 LLMs 🤔</h2><p>[TOC]</p>
<h3 id="🤗-1-基于-LM-Studio"><a href="#🤗-1-基于-LM-Studio" class="headerlink" title="🤗 1. 基于 LM-Studio"></a>🤗 1. 基于 <code>LM-Studio</code></h3><ol>
<li><p>访问 <code>LM-Studio</code>，网址：<a target="_blank" rel="noopener" href="https://lmstudio.ai/">LM Studio - Discover, download, and run local LLMs</a></p>
<p>下载对应系统的安装包，然后双击运行即可。</p>
</li>
</ol>
<img src="./Deploy_LLMs_ON_PC/LM_Studio_Website.png">

<ol start="2">
<li>访问 <code>ModelScope</code><a target="_blank" rel="noopener" href="https://community.modelscope.cn/">魔搭社区</a> 或者 🤗<code>Hugging Face</code><a target="_blank" rel="noopener" href="https://huggingface.co/">Hugging Face</a>，这里以 <code>ModelScope</code> 为例，进入模型库，下载相应模型。</li>
</ol>
<img src="./Deploy_LLMs_ON_PC/ModelScope.png">

<center>魔搭社区官网</center>

<img src="./Deploy_LLMs_ON_PC/ModelScopeDownloadModels.png">

<center>找到需要的模型并下载</center>

<ol start="3">
<li>下载好响应的模型后，将模型组织好，放到相应的文件夹中，这里按照 <code>models/Publisher/Repository/*.gguf</code> 的路径组织模型路径，然后选择 <code>Change</code> 更改模型的位置。如果不按照该路径组织，则会出现 <code>You have 1 uncategorized model files.</code> 错误，如下图所示：</li>
</ol>
<img src="./Deploy_LLMs_ON_PC/Error_With_Wrong_Project_Structure.png">

<img src="./Deploy_LLMs_ON_PC/LM_Studio_Change_ModelFile.png">

<ol start="4">
<li>但是那种方式是不太推荐的，我们组织 <code>USER/MODEL_NAME/*.gguf</code> 的结构，这种结构会比较明了：</li>
</ol>
<img src="./Deploy_LLMs_ON_PC/LM_Studio_Change_ModelFile0002.png">

<ol start="5">
<li>完成模型文件的下载和组织后，我们可以进入聊天页面，选择模型进行加载。这里为了节约空间，我删除了 <code>nilera/Qwen1.5-7B-Chat-Q4-GGUF</code> 目录下的文件。</li>
</ol>
<img src="./Deploy_LLMs_ON_PC/SelectAModel2Load.png">

<ol start="6">
<li>选择模型加载，等待加载完成即可像平时使用其他大模型的时候一样使用这些模型。</li>
</ol>
<img src="./Deploy_LLMs_ON_PC/LM_Studio_Change_Test_qwen1_5.png">

<ol start="7">
<li>但是如果我们想在代码中使用我们的大模型应该怎么做呢？我们可以选择 <code>LM-Studio</code> 的 <code>Local Server</code> 菜单项，选择 <code>Start Server</code> 即可部署到一个本地指定的端口（默认是 <code>1234</code>）。</li>
</ol>
<img src="./Deploy_LLMs_ON_PC/LM_Studio_Change_Start_Local_Server0001.png">

<img src="./Deploy_LLMs_ON_PC/LM_Studio_Change_Start_Local_Server_0002.png">

<ol start="8">
<li>右侧有许多样例，我们可以选择一段样例，如：<code>chat(python)</code>，这里对这段代码进行简单的解释。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Example: reuse your existing OpenAI setup</span></span><br><span class="line"><span class="keyword">from</span> openai <span class="keyword">import</span> OpenAI</span><br><span class="line"></span><br><span class="line"><span class="comment"># Point to the local server</span></span><br><span class="line">client = OpenAI(base_url=<span class="string">&quot;http://localhost:1234/v1&quot;</span>, api_key=<span class="string">&quot;lm-studio&quot;</span>)</span><br><span class="line"></span><br><span class="line">completion = client.chat.completions.create(</span><br><span class="line">  model=<span class="string">&quot;Publisher/Repository&quot;</span>,									<span class="comment"># 可以理解为模型路径, 这里以启动在这个端口的模型为准</span></span><br><span class="line">  messages=[</span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;system&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;Always answer in Chinese.&quot;</span>&#125;,	<span class="comment"># 系统设置: 每次都用中文回答</span></span><br><span class="line">    &#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: <span class="string">&quot;Introduce yourself.&quot;</span>&#125;			<span class="comment"># 对话设置: 这里希望 AI 介绍一下他自己</span></span><br><span class="line">  ],</span><br><span class="line">  temperature=<span class="number">0.7</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(completion.choices[<span class="number">0</span>].message)							<span class="comment"># 获取模型的回复</span></span><br></pre></td></tr></table></figure>

<ol start="9">
<li>然后我们就可以愉快的使用 <code>Python</code> 调用我们的本地大模型了。</li>
</ol>
<h3 id="⛵-2-使用-PowerInfer-框架"><a href="#⛵-2-使用-PowerInfer-框架" class="headerlink" title="⛵ 2. 使用 PowerInfer 框架"></a>⛵ 2. 使用 <code>PowerInfer</code> 框架</h3><p><code>PowerInfer</code> 框架 <em>GitHub</em> 链接：<a target="_blank" rel="noopener" href="https://github.com/SJTU-IPADS/PowerInfer">SJTU-IPADS&#x2F;PowerInfer: High-speed Large Language Model Serving on PCs with Consumer-grade GPUs (github.com)</a></p>
<p>$2024$ 年发布论文 <code>PowerInfer-2</code>：<font color=Blue>[</font><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2406.06282">2406.06282] PowerInfer-2: Fast Large Language Model Inference on a Smartphone (arxiv.org)</a></p>
<p><code>Anaconda</code> 命令使用：<a target="_blank" rel="noopener" href="https://blog.csdn.net/miracleoa/article/details/106115730">【anaconda】conda创建、查看、删除虚拟环境（anaconda命令集）_conda 创建环境-CSDN博客</a></p>
<p>参考博客：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42232045/article/details/135113112">大模型笔记之-3090显卡推理70B参数模型|基于PowerInfer 一个 CPU&#x2F;GPU LLM 推理引擎-CSDN博客</a></p>
<ol>
<li>使用 <code>Conda</code> 创建环境，这里 Python 版本需要大于 <code>3.8</code>：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n powerinfer1 python=3.8</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>激活 <code>Conda</code> 环境：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda activate powerinfer1</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>克隆 <code>PowerInfer</code> 框架代码：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> git@github.com:SJTU-IPADS/PowerInfer.git</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>安装所需依赖：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install -r requirements.txt</span><br></pre></td></tr></table></figure>

<ol start="5">
<li><p>使用 <code>CMake</code> 进行编译（<code>CMake</code> 版本需要大于：<code>3.17+</code>）</p>
<p>这里很大概率可能会出现编译器版本与 CUDA 版本不一致的情况，解决方案：<a target="_blank" rel="noopener" href="https://blog.csdn.net/lishiyu93/article/details/114599859">fatal error C1189: #error: – unsupported Microsoft Visual Studio version! - CSDN博客</a></p>
<p>这里我有三个 <code>CUDA</code> 版本，貌似修改其中任意一个就可以，这里我修改的是 <code>CUDA v11.6</code> 版本。</p>
<p>① 如果是 <code>NVIDIA GPUs</code>，需要使用如下方式进行编译：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cmake -S . -B build -DLLAMA_CUBLAS=ON</span><br><span class="line">cmake --build build --config Release</span><br></pre></td></tr></table></figure>

<p>② 如果是 <code>AMD GPUs</code>，需要使用下面的方式进行编译：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Replace &#x27;1100&#x27; to your card architecture name, you can get it by rocminfo</span></span><br><span class="line">CC=/opt/rocm/llvm/bin/clang CXX=/opt/rocm/llvm/bin/clang++ cmake -S . -B build -</span><br><span class="line">DLLAMA_HIPBLAS=ON -DAMDGPU_TARGETS=gfx1100</span><br><span class="line">cmake --build build --config Release</span><br></pre></td></tr></table></figure>

<p>③ 如果是 <code>CPU ONLY</code>，需要使用下面的方式进行编译：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cmake -S . -B build</span><br><span class="line">cmake --build build --config Release</span><br></pre></td></tr></table></figure>

<p>这里我有一块 <code>Nvidia 1050ti</code> 所以我使用<strong>方式 ①</strong>进行编译。</p>
</li>
<li><p>对于我们下载的模型，可以使用提供的方式进行转化，转化为 PowerInfer 可以使用的类型：</p>
</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># make sure that you have done `pip install -r requirements.txt`</span></span><br><span class="line">python convert.py --outfile /PATH/TO/POWERINFER/GGUF/REPO/MODELNAME.powerinfer.gguf /PATH/TO/ORIGINAL/MODEL /PATH/TO/PREDICTOR</span><br><span class="line"><span class="comment"># python convert.py --outfile ./ReluLLaMA-70B-PowerInfer-GGUF/llama-70b-relu.powerinfer.gguf ./SparseLLM/ReluLLaMA-70B ./PowerInfer/ReluLLaMA-70B-Predictor</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python convert.py --outfile D:/LMStudio/models/Publisher/Repository/qwen1_5-7b-chat-q4_0.gguf ./SparseLLM/ReluLLaMA-70B ./PowerInfer/ReluLLaMA-70B-Predictor</span><br></pre></td></tr></table></figure>

<ol start="7">
<li>或者将要 原始模型转化为 GGUF 模型</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python convert-dense.py --outfile /PATH/TO/DENSE/GGUF/REPO/MODELNAME.gguf /PATH/TO/ORIGINAL/MODEL</span><br></pre></td></tr></table></figure>

<ol start="8">
<li>运行模型</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./build/bin/Release/main.exe -m C:/Users/NilEra/Downloads/llama-7b-relu.powerinfer.gguf -n 128 -t 2 -p <span class="string">&quot;Once upon a time&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 其中/home/user/data/ReluLLaMA-70B-PowerInfer-GGUF/llama-70b-relu.q4.powerinfer.gguf为GPTQ量化过的模型文件</span></span><br></pre></td></tr></table></figure>

<ol start="9">
<li>一些问题：</li>
</ol>
<p><img src="/./Deploy_LLMs_ON_PC/Issues22.png" alt="Issus22"></p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/page/0/">上一页</a></div><div class="pagination-next"><a href="/page/2/">下一页</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><span class="pagination-ellipsis">&hellip;</span></li><li><a class="pagination-link" href="/page/5/">5</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatarMyself.jpg" alt="NilEra"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">NilEra</p><p class="is-size-6 is-block">C/C++ Developer!</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Jinan Shandong</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">41</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">36</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">41</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/NilEra-K" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/NilEra-K"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/NilEra-K" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">GitHub</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="https://nano.chemtian.top/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Thymol Blue</span></span><span class="level-right"><span class="level-item tag">nano.chemtian.top</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/CppDev/"><span class="level-start"><span class="level-item">CppDev</span></span><span class="level-end"><span class="level-item tag">7</span></span></a><ul><li><a class="level is-mobile" href="/categories/CppDev/Gaming/"><span class="level-start"><span class="level-item">Gaming</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CppDev/QT6/"><span class="level-start"><span class="level-item">QT6</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CppDev/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B/"><span class="level-start"><span class="level-item">多线程编程</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CppDev/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"><span class="level-start"><span class="level-item">网络编程</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CppDev/%E8%AF%AD%E6%B3%95%E7%82%B9/"><span class="level-start"><span class="level-item">语法点</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/CppDev/%E8%AF%AD%E6%B3%95%E7%82%B9/bind/"><span class="level-start"><span class="level-item">bind</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CppDev/%E8%AF%AD%E6%B3%95%E7%82%B9/enum-class/"><span class="level-start"><span class="level-item">enum class</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CppDev/%E8%AF%AD%E6%B3%95%E7%82%B9/%E8%99%9A%E5%87%BD%E6%95%B0/"><span class="level-start"><span class="level-item">虚函数</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/%E8%BD%AF%E4%BB%B6%E6%BA%90/"><span class="level-start"><span class="level-item">软件源</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"><span class="level-start"><span class="level-item">大数据技术</span></span><span class="level-end"><span class="level-item tag">8</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/ECharts/"><span class="level-start"><span class="level-item">ECharts</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/HBase/"><span class="level-start"><span class="level-item">HBase</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/Scala/"><span class="level-start"><span class="level-item">Scala</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/Spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"><span class="level-start"><span class="level-item">数据可视化</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">项目</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"><span class="level-start"><span class="level-item">开发工具</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/Axure-RP-9/"><span class="level-start"><span class="level-item">Axure RP 9</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/Docker/"><span class="level-start"><span class="level-item">Docker</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/Git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/VSCode/"><span class="level-start"><span class="level-item">VSCode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构/算法</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/%E5%93%88%E5%B8%8C-Hash/"><span class="level-start"><span class="level-item">哈希(Hash)</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/%E6%A0%88-Stack/"><span class="level-start"><span class="level-item">栈(Stack)</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/%E6%A0%91-Tree/"><span class="level-start"><span class="level-item">树(Tree)</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">9</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Kaggle/"><span class="level-start"><span class="level-item">Kaggle</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/LLMs/"><span class="level-start"><span class="level-item">LLMs</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/PyTorch/"><span class="level-start"><span class="level-item">PyTorch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Stable-Diffusion/"><span class="level-start"><span class="level-item">Stable_Diffusion</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/"><span class="level-start"><span class="level-item">网络架构</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/Kolmogorov-Arnold-Networks/"><span class="level-start"><span class="level-item">Kolmogorov-Arnold Networks</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></li><li><a class="level is-mobile" href="/categories/%E9%97%B2%E8%81%8A/"><span class="level-start"><span class="level-item">闲聊</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E9%97%B2%E8%81%8A/%E8%AE%A1%E5%88%92/"><span class="level-start"><span class="level-item">计划</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-05T07:07:36.000Z">2024-09-05</time></p><p class="title"><a href="/2024/09/05/How2Use-Stable-Diffusion/">How2Use_Stable_Diffusion</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Stable-Diffusion/">Stable_Diffusion</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-08-22T09:58:38.000Z">2024-08-22</time></p><p class="title"><a href="/2024/08/22/Kolmogorov-Arnold-Networks/">Kolmogorov-Arnold Networks</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/">网络架构</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84/Kolmogorov-Arnold-Networks/">Kolmogorov-Arnold Networks</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-08-18T02:35:39.000Z">2024-08-18</time></p><p class="title"><a href="/2024/08/18/Create-AN-Environment-of-Kaggle/">Create_AN_Environment_of_Kaggle</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-08-17T01:24:42.000Z">2024-08-17</time></p><p class="title"><a href="/2024/08/17/RSNA-2024/">RSNA-2024</a></p><p class="categories"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a> / <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Kaggle/">Kaggle</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-08-15T09:21:54.000Z">2024-08-15</time></p><p class="title"><a href="/2024/08/15/Virtual-Destructor-IN-Cpp/">Virtual_Destructor_IN_Cpp</a></p><p class="categories"><a href="/categories/CppDev/">CppDev</a> / <a href="/categories/CppDev/%E8%AF%AD%E6%B3%95%E7%82%B9/">语法点</a> / <a href="/categories/CppDev/%E8%AF%AD%E6%B3%95%E7%82%B9/%E8%99%9A%E5%87%BD%E6%95%B0/">虚函数</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/09/"><span class="level-start"><span class="level-item">九月 2024</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/08/"><span class="level-start"><span class="level-item">八月 2024</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/07/"><span class="level-start"><span class="level-item">七月 2024</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/06/"><span class="level-start"><span class="level-item">六月 2024</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/05/"><span class="level-start"><span class="level-item">五月 2024</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/04/"><span class="level-start"><span class="level-item">四月 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">三月 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Axure-RP-9/"><span class="tag">Axure RP 9</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/C-11-%E6%96%B0%E6%A0%87%E5%87%86/"><span class="tag">C++ 11 新标准</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CppDev/"><span class="tag">CppDev</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Docker/"><span class="tag">Docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ECharts/"><span class="tag">ECharts</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/EasyX/"><span class="tag">EasyX</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GameDev/"><span class="tag">GameDev</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HBase/"><span class="tag">HBase</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hadoop/"><span class="tag">Hadoop</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/JavaDev/"><span class="tag">JavaDev</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KAN/"><span class="tag">KAN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kaggle/"><span class="tag">Kaggle</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LLMs/"><span class="tag">LLMs</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LM-Studio/"><span class="tag">LM-Studio</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/MyBatis-Plus/"><span class="tag">MyBatis-Plus</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PowerInfer/"><span class="tag">PowerInfer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PyTorch/"><span class="tag">PyTorch</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/QT6/"><span class="tag">QT6</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R/"><span class="tag">R</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scala/"><span class="tag">Scala</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spark/"><span class="tag">Spark</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Stable-Diffusion/"><span class="tag">Stable Diffusion</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tomcat/"><span class="tag">Tomcat</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VSCode/"><span class="tag">VSCode</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ZooKeeper/"><span class="tag">ZooKeeper</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%BC%96%E7%A8%8B/"><span class="tag">多线程编程</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"><span class="tag">大数据技术</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><span class="tag">大模型</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"><span class="tag">开发工具</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"><span class="tag">数据结构</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">深度学习</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"><span class="tag">网络编程</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%A1%E5%88%92/"><span class="tag">计划</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AF%AD%E6%B3%95%E7%82%B9/"><span class="tag">语法点</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BD%AF%E4%BB%B6%E6%BA%90/"><span class="tag">软件源</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%97%B2%E8%81%8A/"><span class="tag">闲聊</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%A1%B9%E7%9B%AE/"><span class="tag">项目</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/StarLogo.svg" alt="Hello, NilEra :-)" height="28"></a><p class="is-size-7"><span>&copy; 2024 NilEra</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2024 前方⚡高能</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/NilEra-K"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container" id="algolia-input"></div><div id="algolia-poweredby" style="display:flex;margin:0 .5em 0 1em;align-items:center;line-height:0"></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div><div class="searchbox-footer"></div></div></div><script src="https://cdnjs.loli.net/ajax/libs/algoliasearch/4.0.3/algoliasearch-lite.umd.js" crossorigin="anonymous" defer></script><script src="https://cdnjs.loli.net/ajax/libs/instantsearch.js/4.3.1/instantsearch.production.min.js" crossorigin="anonymous" defer></script><script src="/js/algolia.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadAlgolia({"applicationId":"2TB5ZZYPCO","apiKey":"00a43f1d62ca7b24c8b78d5f0223c065","indexName":"dev_nilera_blog"}, {"hint":"想要查找什么...","no_result":"未找到搜索结果","untitled":"(无标题)","empty_preview":"(无内容预览)"});
        });</script></body></html>