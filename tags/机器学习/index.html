<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><meta name="theme-color" content="#123456"><meta name="generator" content="Hexo 4.2.0"><title>标签: 机器学习 - Hello, NilEra :-)</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hello, NilEra :-)"><meta name="msapplication-TileImage" content="/img/StarLogo.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hello, NilEra :-)"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="努力做自己喜欢的事"><meta property="og:type" content="blog"><meta property="og:title" content="Hello, NilEra :-)"><meta property="og:url" content="https://hello-nilera.com/"><meta property="og:site_name" content="Hello, NilEra :-)"><meta property="og:description" content="努力做自己喜欢的事"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://hello-nilera.com/img/og_image.png"><meta property="article:author" content="NilEra"><meta property="article:tag" content="Hello NilEra"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://hello-nilera.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://hello-nilera.com"},"headline":"Hello, NilEra :-)","image":["https://hello-nilera.com/img/og_image.png"],"author":{"@type":"Person","name":"NilEra"},"publisher":{"@type":"Organization","name":"Hello, NilEra :-)","logo":{"@type":"ImageObject","url":"https://hello-nilera.com/img/StarLogo.svg"}},"description":"努力做自己喜欢的事"}</script><link rel="icon" href="/img/StarLogo.svg"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/6.0.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/11.7.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script>var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?249654dcf9a3bf70708fdfc6e2b1ec2b";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();</script><meta name="msvalidate.01" content="F6BD78C6BD0096D2218CF88334111125"><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.loli.net/ajax/libs/pace/1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/StarLogo.svg" alt="Hello, NilEra :-)" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">目录</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a><a class="navbar-item" href="/me">我</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/NilEra-K"><i class="fab fa-github"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">标签</a></li><li class="is-active"><a href="#" aria-current="page">机器学习</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-05-19T08:33:06.000Z" title="2024/5/19 16:33:06">2024-05-19</time>发表</span><span class="level-item"><time dateTime="2024-05-22T01:49:59.850Z" title="2024/5/22 09:49:59">2024-05-22</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span> / </span><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Kaggle/">Kaggle</a></span><span class="level-item">38 分钟读完 (大约5697个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/05/19/BELKA-2024/">BELKA_2024</a></p><div class="content"><p>[TOC]</p>
<h1 id="Leash-Bio-Predict-New-Medicines-with-BELKA"><a href="#Leash-Bio-Predict-New-Medicines-with-BELKA" class="headerlink" title="Leash Bio - Predict New Medicines with BELKA"></a>Leash Bio - Predict New Medicines with BELKA</h1><p>用 <em><strong>BELKA</strong></em> 预测新药</p>
<p>Predict small molecule-protein interactions using the Big Encoded Library for Chemical Assessment (BELKA)</p>
<p>使用化学评估大编码库（BELKA）预测小分子蛋白质相互作用</p>
<h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p>In this competition, you’ll develop machine learning (ML) models to predict the binding affinity of small molecules to specific protein targets – a critical step in drug development for the pharmaceutical industry that would pave the way for more accurate drug discovery. You’ll help predict which drug-like small molecules (chemicals) will bind to three possible protein targets.</p>
<p>在这场比赛中，你将开发机器学习（ML）模型来预测小分子与特定<strong>蛋白质靶标（目标蛋白）</strong>的结合亲和力——这是制药行业药物开发的关键一步，将为更准确的药物发现铺平道路。你将帮助预测哪种药物样的小分子（化学物质）将与三种可能的蛋白质靶点结合。</p>
<h2 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h2><p>Small molecule drugs are chemicals that interact with cellular protein machinery and affect the functions of this machinery in some way. Often, drugs are meant to inhibit the activity of single protein targets, and those targets are thought to be involved in a disease process. A classic approach to identify such candidate molecules is to physically make them, one by one, and then expose them to the protein target of interest and test if the two interact. This can be a fairly laborious and time-intensive process.</p>
<p><em>小分子药物是与细胞蛋白质机制相互作用并以某种方式影响该机制功能的化学物质。通常，药物旨在抑制单个蛋白质靶标的活性，而这些靶标被认为与疾病过程有关。识别这类候选分子的一种经典方法是一个接一个地进行物理制造，然后将其暴露于感兴趣的蛋白质靶点，并测试两者是否相互作用。这可能是一个相当费力和耗时的过程。</em></p>
<p>The US Food and Drug Administration (FDA) has approved roughly <a target="_blank" rel="noopener" href="https://www.fda.gov/drugs/development-approval-process-drugs/new-drugs-fda-cders-new-molecular-entities-and-new-therapeutic-biological-products">2,000 novel molecular entities</a> in its <a target="_blank" rel="noopener" href="https://www.fda.gov/about-fda/histories-fda-regulated-products/summary-nda-approvals-receipts-1938-present">entire history</a>. However, the number of chemicals in druglike space has been <a target="_blank" rel="noopener" href="https://www.nature.com/articles/432823a">estimated to be 10^60</a>, a space far too big to physically search. There are likely effective treatments for human ailments hiding in that chemical space, and better methods to find such treatments are desirable to us all.</p>
<p><em>美国食品药品监督管理局（FDA）已经批准了大约<a target="_blank" rel="noopener" href="https://www.fda.gov/drugs/development-approval-process-drugs/new-drugs-fda-cders-new-molecular-entities-and-new-therapeutic-biological-products">2000种新型分子实体</a>在其<a target="_blank" rel="noopener" href="https://www.fda.gov/about-fda/histories-fda-regulated-products/summary-nda-approvals-receipts-1938-present">整个历史</a>. 然而，类药物领域的化学物质数量<a target="_blank" rel="noopener" href="https://www.nature.com/articles/432823a">估计为$10^60$</a>，这个空间太大了，无法进行物理搜索。在这个化学空间里，可能有有效的治疗人类疾病的方法，而找到更好的治疗方法对我们所有人来说都是可取的。</em></p>
<p>To evaluate potential search methods in small molecule chemistry, competition host Leash Biosciences physically tested some 133M small molecules for their ability to interact with one of three protein targets using DNA-encoded chemical library (DEL) technology. This dataset, the Big Encoded Library for Chemical Assessment (BELKA), provides an excellent opportunity to develop predictive models that may advance drug discovery.</p>
<p><em>为了评估小分子化学中潜在的搜索方法，比赛主办方Leash Biosciences使用DNA编码化学文库（DEL）技术对约133M个小分子进行了物理测试，以确定它们与三个蛋白质靶标之一相互作用的能力。该数据集，即化学评估大编码库（BELKA），为开发可能促进药物发现的预测模型提供了极好的机会。</em></p>
<p>Datasets of this size are rare and restricted to large pharmaceutical companies. The current best-curated public dataset of this kind is perhaps <a target="_blank" rel="noopener" href="https://www.bindingdb.org/rwd/bind/index.jsp">bindingdb</a>, which, at 2.8M binding measurements, is much smaller than BELKA.</p>
<p><em>这种规模的数据集非常罕见，仅限于大型制药公司。目前这类最好的公共数据集可能是<a target="_blank" rel="noopener" href="https://www.bindingdb.org/rwd/bind/index.jsp">bindingdb</a>，在2.8M的结合测量值下，比BELKA小得多。</em></p>
<p>This competition aims to revolutionize small molecule binding prediction by harnessing ML techniques. Recent advances in ML approaches suggest it might be possible to search chemical space by inference using well-trained computational models rather than running <a target="_blank" rel="noopener" href="https://blog.research.google/2020/06/unlocking-chemome-with-dna-encoded.html">laboratory</a> <a target="_blank" rel="noopener" href="https://pubs.acs.org/doi/10.1021/acs.jmedchem.0c00452">experiments</a>. Similar progress in <a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">other</a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">fields</a> suggest using ML to search across vast spaces could be a generalizable approach applicable to many domains. We hope that by providing BELKA we will democratize aspects of computational drug discovery and assist the community in finding new lifesaving medicines.</p>
<p><em>这项竞赛旨在通过利用ML技术彻底改变小分子结合预测。ML方法的最新进展表明，使用训练有素的计算模型而不是进行<a target="_blank" rel="noopener" href="https://blog.research.google/2020/06/unlocking-chemome-with-dna-encoded.html">实验室</a> <a target="_blank" rel="noopener" href="https://pubs.acs.org/doi/10.1021/acs.jmedchem.0c00452">实验</a>，通过推理搜索化学空间是可能的。<a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">其他</a> <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">领域</a>的类似进展表明，使用ML在广阔的空间中搜索可能是一种适用于许多领域的通用方法。我们希望通过提供BELKA，我们将使计算药物发现的各个方面民主化，并帮助社区寻找新的救命药物。</em></p>
<p>Here, you’ll build predictive models to estimate the binding affinity of unknown chemical compounds to specified protein targets. You may use the training data provided; alternatively, there are a number of methods to make small molecule binding predictions without relying on empirical binding data (e.g. <a target="_blank" rel="noopener" href="https://github.com/gcorso/DiffDock">DiffDock</a>, and this contest was designed to allow for such submissions).</p>
<p><em>在这里，你将建立预测模型来估计未知化合物与特定蛋白质靶标的结合亲和力。您可以使用提供的培训数据；或者，有许多方法可以在不依赖经验结合数据的情况下进行小分子结合预测（例如<a target="_blank" rel="noopener" href="https://github.com/gcorso/DiffDock">DiffDock</a>，而本次竞赛旨在允许此类提交）。</em></p>
<p>Your work will contribute to advances in small molecule chemistry used to accelerate drug discovery.</p>
<p><em>你的工作将有助于促进用于加速药物发现的小分子化学的进步。</em></p>
<h2 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h2><p>This metric for this competition is the average precision calculated for each (protein, split group) and then averaged for the final score. Please see this <a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/leash-BELKA/discussion/503232">forum post</a> for important details.</p>
<p><em>这项比赛的指标是为每个（蛋白质、分组）计算的平均精度，然后为最终得分取平均值。请参阅此<a target="_blank" rel="noopener" href="https://www.kaggle.com/competitions/leash-BELKA/discussion/503232">论坛帖子</a>了解重要细节。</em></p>
<p>Here’s the <a target="_blank" rel="noopener" href="https://www.kaggle.com/code/metric/leash-average-map">code</a> for the implementation.</p>
<p><em>这是<a target="_blank" rel="noopener" href="https://www.kaggle.com/code/metric/leash-average-map">代码</a>以供实施。</em></p>
<h3 id="Submission-File"><a href="#Submission-File" class="headerlink" title="Submission File"></a>Submission File</h3><p>For each <code>id</code> in the test set, you must predict a probability for the binary target <code>binds</code> target. The file should contain a header and have the following format:</p>
<p><em>对于测试集中的每个</em><code>id</code>，<em>您必须预测二进制目标“绑定”目标的概率。该文件应包含一个标头，并具有以下格式：</em></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">id,binds</span><br><span class="line">295246830,0.5</span><br><span class="line">295246831,0.5</span><br><span class="line">295246832,0.5</span><br><span class="line">etc.</span><br></pre></td></tr></table></figure>

<h2 id="Timeline"><a href="#Timeline" class="headerlink" title="Timeline"></a>Timeline</h2><ul>
<li><strong>April 4, 2024</strong> - Start Date.</li>
<li><strong>July 1, 2024</strong> - Entry Deadline. You must accept the competition rules before this date in order to compete.</li>
<li><strong>July 1, 2024</strong> - Team Merger Deadline. This is the last day participants may join or merge teams.</li>
<li><strong>July 8, 2024</strong> - Final Submission Deadline.</li>
</ul>
<p>All deadlines are at 11:59 PM UTC on the corresponding day unless otherwise noted. The competition organizers reserve the right to update the contest timeline if they deem it necessary.</p>
<h2 id="Prizes"><a href="#Prizes" class="headerlink" title="Prizes"></a>Prizes</h2><ul>
<li>First Prize: $12,000</li>
<li>Second Prize: $10,000</li>
<li>Third Prize: $10,000</li>
<li>Fourth Prize: $8,000</li>
<li>Fifth Prize: $5,000</li>
<li>Top Student Group: $5,000 to the highest performing student team. A team would be considered a student team if majority members (e.g. at least 3 out of a 5 member team) are students enrolled in a high school or university degree. In the case of an even number of members, half of them must be students.</li>
</ul>
<h2 id="Competition-Host"><a href="#Competition-Host" class="headerlink" title="Competition Host"></a>Competition Host</h2><p><a target="_blank" rel="noopener" href="https://www.leash.bio/">Leash Biosciences</a> is a discovery-stage biotechnology company that seeks to improve medicinal chemistry with machine learning approaches and massive data collection. Leash is comprised of wet lab scientists and dry lab scientists in equal numbers, and is proudly headquartered in Salt Lake City, Utah, USA.</p>
<h2 id="Additional-Details"><a href="#Additional-Details" class="headerlink" title="Additional Details"></a>Additional Details</h2><h3 id="Chemical-Representations"><a href="#Chemical-Representations" class="headerlink" title="Chemical Representations"></a>Chemical Representations</h3><p>One of the goals of this competition is to explore and compare many different ways of representing molecules. Small molecules <a target="_blank" rel="noopener" href="https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-00460-5">have</a> <a target="_blank" rel="noopener" href="https://wires.onlinelibrary.wiley.com/doi/10.1002/wcms.1603">been</a> [represented](<a target="_blank" rel="noopener" href="https://pubs.acs.org/doi/10.1021/acsinfocus.7e7006?ref=infocus/AI_&">https://pubs.acs.org/doi/10.1021/acsinfocus.7e7006?ref=infocus%2FAI_&amp;</a> Machine Learning) <a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10689004/">with</a> SMILES, graphs, 3D structures, and more, including more esoteric methods <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1801.10130">such as spherical convolutional neural nets</a>. We encourage competitors to explore not only different methods of making predictions but also to try different ways of representing the molecules.</p>
<p>We provide the molecules in SMILES format.</p>
<p><em>这场比赛的目标之一是探索和比较许多不同的分子表现方式。小分子已经用SMILES、图形、3D结构等表示，包括更深奥的方法，如球形卷积神经网络。我们鼓励竞争对手不仅探索不同的预测方法，还尝试不同的分子表示方法。</em></p>
<p><em>我们提供SMILES格式的分子。</em></p>
<h3 id="SMILES"><a href="#SMILES" class="headerlink" title="SMILES"></a>SMILES</h3><p>SMILES is a concise string notation used to represent the structure of chemical molecules. It encodes the molecular graph, including atoms, bonds, connectivity, and stereochemistry as a linear sequence of characters, by traversing the molecule graph. SMILES is widely used in machine learning applications for chemistry, such as molecular property prediction, drug discovery, and materials design, as it provides a standardized and machine-readable format for representing and manipulating chemical structures.</p>
<p>The SMILES in this dataset should be sufficient to be translated into any other chemical representation format that you want to try. A simple way to perform some of these translations is with <a target="_blank" rel="noopener" href="https://www.rdkit.org/docs/GettingStartedInPython.html">RDKit</a>.</p>
<p><em>SMILES是一种简明的字符串表示法，用于表示化学分子的结构。它通过遍历分子图，将分子图（包括原子、键、连接性和立体化学）编码为线性字符序列。SMILES广泛用于化学的机器学习应用，如分子性质预测、药物发现和材料设计，因为它为表示和操纵化学结构提供了标准化和机器可读的格式。</em><br><em>该数据集中的SMILES应该足以转换为您想要尝试的任何其他化学表示格式。执行其中一些翻译的一种简单方法是使用<a target="_blank" rel="noopener" href="https://www.rdkit.org/docs/GettingStartedInPython.html">RDKit</a>.</em></p>
<h3 id="Details-about-the-experiments"><a href="#Details-about-the-experiments" class="headerlink" title="Details about the experiments"></a>Details about the experiments</h3><h3 id="DELs-are-libraries-of-small-molecules-with-unique-DNA-barcodes-covalently-attached"><a href="#DELs-are-libraries-of-small-molecules-with-unique-DNA-barcodes-covalently-attached" class="headerlink" title="DELs are libraries of small molecules with unique DNA barcodes covalently attached"></a>DELs are libraries of small molecules with unique DNA barcodes covalently attached</h3><p>Traditional <a target="_blank" rel="noopener" href="https://www.nature.com/articles/nrd3368">high-throughput screening</a> requires keeping individual small molecules in separate, identifiable tubes and demands a lot of liquid handling to test each one of those against the protein target of interest in a separate reaction. The logistical overhead of these efforts tends to restrict screening collections, called libraries, to 50K-5M small molecules. A scalable solution to this problem, DNA-encoded chemical libraries, was <a target="_blank" rel="noopener" href="https://www.nature.com/articles/nchembio.211">described in 2009</a>. As DNA sequencing got <a target="_blank" rel="noopener" href="https://www.genome.gov/about-genomics/fact-sheets/Sequencing-Human-Genome-cost">cheaper and cheaper</a>, it became clear that DNA itself could be used as a label to identify, and deconvolute, collections of molecules in a complex mixture. <a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41573-023-00713-6">DELs</a> <a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8369695/">leverage</a> this DNA sequencing technology.</p>
<p>These barcoded small molecules are in a pool (many in a single tube, rather than one tube per small molecule) and are exposed to the protein target of interest in solution. The protein target of interest is then rinsed to remove small molecules in the DEL that don’t bind the target, and the remaining binders are collected and their DNA sequenced.</p>
<p><strong>DEL是共价连接有独特DNA条形码的小分子库</strong><br><em>传统<a target="_blank" rel="noopener" href="https://www.nature.com/articles/nrd3368">高通量筛选</a>需要将单个小分子保持在单独的、可识别的管中，并且需要大量的液体处理来在单独的反应中针对感兴趣的蛋白质靶标测试其中的每一个。这些工作的后勤开销往往将筛选收藏（称为文库）限制在5000万至500万个小分子以内。这个问题的一个可扩展的解决方案，DNA编码的化学文库，<a target="_blank" rel="noopener" href="https://www.nature.com/articles/nchembio.211">在2009年描述</a>. 随着DNA测序变得<a target="_blank" rel="noopener" href="https://www.genome.gov/about-genomics/fact-sheets/Sequencing-Human-Genome-cost">越来越便宜</a>，很明显，DNA本身可以用作标签来识别和消除复杂混合物中分子的聚集。<a target="_blank" rel="noopener" href="https://www.nature.com/articles/s41573-023-00713-6%E5%BD%B1%E5%93%8D%E5%8A%9Bhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC8369695/">DELs</a>这种DNA测序技术。</em><br><em>这些条形码小分子在一个池中（许多在单管中，而不是每个小分子一管），并暴露于溶液中感兴趣的蛋白质靶标。然后冲洗感兴趣的蛋白质靶标，以去除DEL中不与靶标结合的小分子，收集剩余的结合物并对其DNA进行测序。</em></p>
<h3 id="DELs-are-manufactured-by-combining-different-building-blocks"><a href="#DELs-are-manufactured-by-combining-different-building-blocks" class="headerlink" title="DELs are manufactured by combining different building blocks"></a>DELs are manufactured by combining different building blocks</h3><p>An intuitive way to think about DELs is to imagine a Mickey Mouse head as an example of a small molecule in the DEL. We attach the DNA barcode to Mickey’s chin. Mickey’s left ear is connected by a zipper; Mickey’s right ear is connected by velcro. These attachment points of zippers and velcro are analogies to different chemical reactions one might use to construct the DEL.</p>
<p>We could purchase ten different Mickey Mouse faces, ten different zipper ears, and ten different velcro ears, and use them to construct our small molecule library. By creating every combination of these three, we’ll have 1,000 small molecules, but we only needed thirty building blocks (faces and ears) to make them. This combinatorial approach is what allows DELs to have so many members: the library in this competition is composed of 133M small molecules. The 133M small molecule library used here, AMA014, was provided by <a target="_blank" rel="noopener" href="https://www.alphama.com.cn/en/about/">AlphaMa</a>. It has a triazine core and superficially resembles the DELs described <a target="_blank" rel="noopener" href="https://www.nature.com/articles/nchembio.211">here</a>.</p>
<p><strong>DEL是通过组合不同的构建块来制造的</strong><br>一个思考DEL的直观方法是想象一个米老鼠的头作为DEL中一个小分子的例子。我们把DNA条形码贴在米奇的下巴上。米奇的左耳由拉链连接；米奇的右耳是用尼龙搭扣连接的。拉链和尼龙搭扣的这些连接点类似于可能用于构建DEL的不同化学反应。<br>我们可以购买十个不同的米老鼠脸、十个不同拉链耳朵和十个不同尼龙搭扣耳朵，并用它们来构建我们的小分子库。通过创建这三者的每一个组合，我们将拥有1000个小分子，但我们只需要30个构建块（脸和耳朵）就可以制造它们。这种组合方法使DEL能够拥有如此多的成员：这场竞争中的文库由133M个小分子组成。这里使用的133M小分子文库AMA014由<a target="_blank" rel="noopener" href="https://www.alphama.com.cn/en/about/">AlphaMa</a>提供。它有一个三嗪核心，表面上类似于<a target="_blank" rel="noopener" href="https://www.nature.com/articles/nchembio.211">此处</a>描述的DEL。</p>
<img src="https://www.googleapis.com/download/storage/v1/b/kaggle-user-content/o/inbox%2F1095143%2F1901c6caa0c6c011617f4dec525d7bbe%2FKaggle%20v2%20(1).png?generation=1712179256934503&alt=media">

<h2 id="Acknowledgements"><a href="#Acknowledgements" class="headerlink" title="Acknowledgements"></a>Acknowledgements</h2><p>Leash Biosciences is grateful for the generous cosponsorship of <a target="_blank" rel="noopener" href="https://www.topharvestcap.com/">Top Harvest Capital</a> and <a target="_blank" rel="noopener" href="https://www.alphama.com.cn/en/about/">AlphaMa</a>.</p>
<h2 id="Citation"><a href="#Citation" class="headerlink" title="Citation"></a>Citation</h2><p>Andrew Blevins, Ian K Quigley, Brayden J Halverson, Nate Wilkinson, Rebecca S Levin, Agastya Pulapaka, Walter Reade, Addison Howard. (2024). Leash Bio - Predict New Medicines with BELKA. Kaggle. <a target="_blank" rel="noopener" href="https://kaggle.com/competitions/leash-BELKA">https://kaggle.com/competitions/leash-BELKA</a></p>
<hr>
<h2 id="Dataset-Description"><a href="#Dataset-Description" class="headerlink" title="Dataset Description"></a>Dataset Description</h2><h2 id="Overview-1"><a href="#Overview-1" class="headerlink" title="Overview"></a><strong>Overview</strong></h2><p>The examples in the competition dataset are represented by a binary classification of whether a given small molecule is a binder or not to one of three protein targets. The data were collected using DNA-encoded chemical library (DEL) technology.</p>
<p><em>比赛数据集中的例子由给定小分子是否与三个蛋白质靶标之一结合的二元分类表示。使用DNA编码化学文库（DEL）技术收集数据。</em></p>
<p>We represent chemistry with SMILES (<a target="_blank" rel="noopener" href="https://archive.epa.gov/med/med_archive_03/web/html/smiles.html">Simplified Molecular-Input Line-Entry System</a>) and the labels as binary binding classifications, one per protein target of three targets.</p>
<p>我们用SMILES（<a target="_blank" rel="noopener" href="https://archive.epa.gov/med/med_archive_03/web/html/smiles.html">简化分子输入 行输入系统</a>)和二元绑定分类来表示化学，三个靶标中的每个蛋白质靶标都有一个。</p>
<h2 id="Files"><a href="#Files" class="headerlink" title="Files"></a><strong>Files</strong></h2><p><strong>[train&#x2F;test].[csv&#x2F;parquet]</strong> - The train or test data, available in both the csv and parquet formats.</p>
<ul>
<li><code>id</code> - A unique example_id that we use to identify the molecule-binding target pair.</li>
<li><code>buildingblock1_smiles</code> - The structure, in SMILES, of the first building block</li>
<li><code>buildingblock2_smiles</code> - The structure, in SMILES, of the second building block</li>
<li><code>buildingblock3_smiles</code> - The structure, in SMILES, of the third building block</li>
<li><code>molecule_smiles</code> - The structure of the fully assembled molecule, in SMILES. This includes the three building blocks and the triazine core. Note we use a <code>[Dy]</code> as the stand-in for the DNA linker.</li>
<li><code>protein_name</code> - The protein target name</li>
<li><code>binds</code> - The target column. A binary class label of whether the molecule binds to the protein. Not available for the test set.</li>
</ul>
<p><strong>sample_submission.csv</strong> - A sample submission file in the correct format</p>
<p><strong>[train&#x2F;test].[csv&#x2F;parquet]</strong> - 训练或测试数据，csv和parquet格式均可。</p>
<ul>
<li><code>id</code> - 我们用来识别分子结合靶标对的唯一示例_id。</li>
<li><code>buildingblock1_smiles</code> - 第一个构建块的结构，以SMILES表示</li>
<li><code>buildingblock2_smiles</code> - 第二个构建块的结构，以SMILES表示</li>
<li><code>buildingblock3_smiles</code> - 第三个构建块的结构，以SMILES表示</li>
<li><code>molecule_smiles</code> - 完全组装的分子的结构，以SMILES表示。这包括三个构建块和三嗪核心。请注意，我们使用<code>[Dy]</code>作为DNA连接子的替代。</li>
<li><code>protein_name</code> - 蛋白质靶标名称</li>
<li><code>binds</code> - 目标列。分子是否与蛋白质结合的二进制类标签。不适用于测试集。</li>
</ul>
<h2 id="Competition-data"><a href="#Competition-data" class="headerlink" title="Competition data"></a><strong>Competition data</strong></h2><p>All data were generated in-house at Leash Biosciences. We are providing roughly 98M training examples per protein, 200K validation examples per protein, and 360K test molecules per protein. To test generalizability, the test set contains building blocks that are not in the training set. These datasets are very imbalanced: roughly 0.5% of examples are classified as binders; we used 3 rounds of selection in triplicate to identify binders experimentally. Following the competition, Leash will make all the data available for future use (3 targets × 3 rounds of selection × 3 replicates × 133M molecules, or 3.6B measurements).</p>
<p><em>所有数据均由Leash Biosciences公司内部生成。我们为每种蛋白质提供了大约 98M 个训练实例，为每种蛋白提供了 200K 个验证实例，为每个蛋白质提供了 360K 个测试分子。为了测试可推广性，测试集包含不在训练集中的构建块。这些数据集非常不平衡：大约0.5%的示例被归类为绑定；我们使用了三轮一式三份的选择来实验鉴定粘合剂。比赛结束后，Leash将提供所有数据供未来使用（3个靶标×3轮选择×3个重复×3.33M个分子，或3.6B测量值）。</em></p>
<h2 id="Targets"><a href="#Targets" class="headerlink" title="Targets"></a><strong>Targets</strong></h2><p>Proteins are encoded in the genome, and names of the genes encoding those proteins are typically bestowed by their discoverers and regulated by the <a target="_blank" rel="noopener" href="https://www.genenames.org/">Hugo Gene Nomenclature Committee</a>. The protein products of these genes can sometimes have different names, often due to the history of their discovery.</p>
<p>We screened three protein targets for this competition.</p>
<p>蛋白质在基因组中编码，编码这些蛋白质的基因的名称通常由其发现者命名，并由<a target="_blank" rel="noopener" href="https://www.genenames.org/">雨果基因命名委员会</a>监管。这些基因的蛋白质产物有时可能有不同的名称，通常是由于它们的发现历史。<br>我们为这次比赛筛选了三个蛋白质靶点。</p>
<h3 id="EPHX2-sEH"><a href="#EPHX2-sEH" class="headerlink" title="EPHX2 (sEH)"></a><strong>EPHX2 (sEH)</strong></h3><p>The first target, epoxide hydrolase 2, is encoded by the EPHX2 genetic locus, and its protein product is commonly named “soluble epoxide hydrolase”, or abbreviated to sEH. Hydrolases are enzymes that catalyze certain chemical reactions, and EPHX2&#x2F;sEH also hydrolyzes certain phosphate groups. EPHX2&#x2F;sEH is a potential drug target for high blood pressure and diabetes progression, and small molecules inhibiting EPHX2&#x2F;sEH from earlier DEL efforts <a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8429121/">made it to clinical trials</a>.</p>
<p>EPHX2&#x2F;sEH was also screened with DELs, and hits predicted with ML approaches, in a <a target="_blank" rel="noopener" href="https://blog.research.google/2020/06/unlocking-chemome-with-dna-encoded.html">recent</a> <a target="_blank" rel="noopener" href="https://pubs.acs.org/doi/10.1021/acs.jmedchem.0c00452">study</a> but the screening data were not published. We included EPHX2&#x2F;sEH to allow contestants an external gut check for model performance by comparing to these previously-published results.</p>
<p>We screened EPHX2&#x2F;sEH <a target="_blank" rel="noopener" href="https://www.caymanchem.com/product/10011669/soluble-epoxide-hydrolase-(human-recombinant)">purchased from Cayman Chemical</a>, a life sciences commercial vendor. For those contestants wishing to incorporate protein structural information in their submissions, the amino sequence is positions 2-555 from UniProt entry <a target="_blank" rel="noopener" href="https://www.uniprot.org/uniprotkb/P34913/entry#sequences">P34913</a>, the crystal structure can be found in <a target="_blank" rel="noopener" href="https://www.rcsb.org/structure/3i28">PDB entry 3i28</a>, and predicted structure can be found in AlphaFold2 entry <a target="_blank" rel="noopener" href="https://alphafold.ebi.ac.uk/entry/P34913">34913</a>. Additional EPHX2&#x2F;sEH crystal structures with ligands bound can be found in PDB.</p>
<p>第一个靶标环氧化物水解酶2由EPHX2基因座编码，其蛋白产物通常被命名为“可溶性环氧化物水解酶”，或缩写为sEH。水解酶是催化某些化学反应的酶，EPHX2&#x2F;sEH也水解某些磷酸基团。EPHX2&#x2F;sEH是高血压和糖尿病进展的潜在药物靶点，早期DEL研究中抑制EPHX2&#x2F;s EH的小分子<a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8429121/">已进入临床试验</a>.<br>EPHX2&#x2F;sEH也用DEL进行了筛选，并用ML方法预测了命中率(<a target="_blank" rel="noopener" href="https://blog.research.google/2020/06/unlocking-chemome-with-dna-encoded.html%E5%AD%A6%E4%B9%A0https://pubs.acs.org/doi/10.1021/acs.jmedchem.0c00452)%E4%BD%86%E7%AD%9B%E9%80%89%E6%95%B0%E6%8D%AE%E6%B2%A1%E6%9C%89%E5%85%AC%E5%B8%83%E3%80%82%E6%88%91%E4%BB%AC%E7%BA%B3%E5%85%A5%E4%BA%86EPHX2/sEH%EF%BC%8C%E9%80%9A%E8%BF%87%E4%B8%8E%E4%B9%8B%E5%89%8D%E5%85%AC%E5%B8%83%E7%9A%84%E7%BB%93%E6%9E%9C%E8%BF%9B%E8%A1%8C%E6%AF%94%E8%BE%83%EF%BC%8C%E8%AE%A9%E5%8F%82%E8%B5%9B%E8%80%85%E8%83%BD%E5%A4%9F%E5%AF%B9%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E8%BF%9B%E8%A1%8C%E5%A4%96%E9%83%A8%E6%A3%80%E6%9F%A5%E3%80%82">https://blog.research.google/2020/06/unlocking-chemome-with-dna-encoded.html学习https://pubs.acs.org/doi/10.1021/acs.jmedchem.0c00452)但筛选数据没有公布。我们纳入了EPHX2/sEH，通过与之前公布的结果进行比较，让参赛者能够对模型性能进行外部检查。</a><br>我们筛选了EPHX2&#x2F;sEH<a target="_blank" rel="noopener" href="https://www.caymanchem.com/product/10011669/soluble-epoxide-hydrolase-%EF%BC%88%E4%BA%BA%E7%B1%BB%E9%87%8D%E7%BB%84%EF%BC%89%EF%BC%89%EF%BC%8C%E4%B8%80%E5%AE%B6%E7%94%9F%E5%91%BD%E7%A7%91%E5%AD%A6%E5%95%86%E4%B8%9A%E4%BE%9B%E5%BA%94%E5%95%86%E3%80%82%E5%AF%B9%E4%BA%8E%E9%82%A3%E4%BA%9B%E5%B8%8C%E6%9C%9B%E5%9C%A8%E5%8F%82%E8%B5%9B%E4%BD%9C%E5%93%81%E4%B8%AD%E5%8A%A0%E5%85%A5%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%93%E6%9E%84%E4%BF%A1%E6%81%AF%E7%9A%84%E5%8F%82%E8%B5%9B%E8%80%85%EF%BC%8C%E6%B0%A8%E5%9F%BA%E9%85%B8%E5%BA%8F%E5%88%97%E4%BD%8D%E4%BA%8EUniProt%E6%9D%A1%E7%9B%AE%E7%9A%842-555%E4%BD%8D[P34913](https://www.uniprot.org/uniprotkb/P34913/entry#sequences)%EF%BC%8C%E6%99%B6%E4%BD%93%E7%BB%93%E6%9E%84%E5%8F%AF%E4%BB%A5%E5%9C%A8[PDB%E6%9D%A1%E7%9B%AE3i28]%E4%B8%AD%E6%89%BE%E5%88%B0(https://www.rcsb.org/structure/3i28)%EF%BC%8C%E9%A2%84%E6%B5%8B%E7%BB%93%E6%9E%84%E5%8F%AF%E5%9C%A8AlphaFold2%E6%9D%A1%E7%9B%AE[34913]%E4%B8%AD%E6%89%BE%E5%88%B0(https://alphafold.ebi.ac.uk/entry/P34913">购自开曼化学</a>. 在PDB中可以发现具有结合配体的额外的EPHX2&#x2F;sEH晶体结构。</p>
<h3 id="BRD4"><a href="#BRD4" class="headerlink" title="BRD4"></a><strong>BRD4</strong></h3><p>The second target, bromodomain 4, is encoded by the BRD4 locus and its protein product is also named BRD4. Bromodomains bind to protein spools in the nucleus that DNA wraps around (called histones) and affect the likelihood that the DNA nearby is going to be transcribed, producing new gene products. Bromodomains play roles in cancer progression and a number of drugs <a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10096006/">have been discovered to inhibit their activities</a>.</p>
<p>BRD4 <a target="_blank" rel="noopener" href="https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b01670">has been screened with DEL approaches previously</a> but the screening data were not published. We included BRD4 to allow contestants to evaluate candidate molecules for oncology indications.</p>
<p>We screened BRD4 <a target="_blank" rel="noopener" href="https://www.activemotif.com/catalog/details/31594/recombinant-brd4-44-460-protein">purchased from Active Motif</a>, a life sciences commercial vendor. For those contestants wishing to incorporate protein structural information in their submissions, the amino acid sequence is positions 44-460 from UniProt entry <a target="_blank" rel="noopener" href="https://www.uniprot.org/uniprotkb/O60885/entry#sequences">O60885-1</a>, the crystal structure (for a single domain) can be found in PDB entry <a target="_blank" rel="noopener" href="https://www.rcsb.org/structure/7USK">7USK</a> and predicted structure can be found in AlphaFold2 entry <a target="_blank" rel="noopener" href="https://alphafold.ebi.ac.uk/entry/O60885">O60885</a>. Additional BRD4 crystal structures with ligands bound can be found in PDB.</p>
<h3 id="ALB-HSA"><a href="#ALB-HSA" class="headerlink" title="ALB (HSA)"></a><strong>ALB (HSA)</strong></h3><p>The third target, serum albumin, is encoded by the ALB locus and its protein product is also named ALB. The protein product is sometimes abbreviated as HSA, for “human serum albumin”. ALB, the most <a target="_blank" rel="noopener" href="https://www.ncbi.nlm.nih.gov/books/NBK459198/">common protein in the blood</a>, is used to drive osmotic pressure (to bring fluid back from tissues into blood vessels) and to transport many ligands, hormones, fatty acids, and more.</p>
<p>Albumin, being the most abundant protein in the blood, often plays a role in absorbing candidate drugs in the body and sequestering them from their target tissues. Adjusting candidate drugs to bind less to albumin and other blood proteins <a target="_blank" rel="noopener" href="https://pubs.acs.org/doi/10.1021/acsptsci.2c00115">is a strategy to help these candidate drugs be more effective</a>.</p>
<p>ALB <a target="_blank" rel="noopener" href="https://pubmed.ncbi.nlm.nih.gov/25650139/">has been screened with DEL approaches previously</a> but the screening data were not published. We included ALB to allow contestants to build models that might have a larger impact on drug discovery across many disease types. The ability to predict ALB binding well would allow drug developers to improve their candidate small molecule therapies much more quickly than physically manufacturing many variants and testing them against ALB empirically in an iterative process.</p>
<p>We screened ALB <a target="_blank" rel="noopener" href="https://www.abcam.com/products/proteins-peptides/recombinant-human-serum-albumin-protein-his-tag-ab217817.html">purchased from Active Motif</a>. For those contestants wishing to incorporate protein structural information in their submissions, the amino acid sequence is positions 25 to 609 from UniProt entry <a target="_blank" rel="noopener" href="https://www.uniprot.org/uniprotkb/P02768/entry#sequences">P02768</a>, the crystal structure can be found in PDB entry <a target="_blank" rel="noopener" href="https://www.ebi.ac.uk/pdbe/entry/pdb/1AO6">1AO6</a>, and predicted structure can be found in AlphaFold2 entry <a target="_blank" rel="noopener" href="https://alphafold.ebi.ac.uk/entry/P02768">P02768</a>. Additional ALB crystal structures with ligands bound can be found in PDB.</p>
<p>Good luck!</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2024-03-20T00:21:24.000Z" title="2024/3/20 08:21:24">2024-03-20</time>发表</span><span class="level-item"><time dateTime="2024-05-05T08:34:23.243Z" title="2024/5/5 16:34:23">2024-05-05</time>更新</span><span class="level-item"><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><span> / </span><a class="link-muted" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/PyTorch/">PyTorch</a></span><span class="level-item">1 小时读完 (大约6804个字)</span></div></div><p class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2024/03/20/PyTorch%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E6%8C%87%E5%8D%97/">PyTorch快速上手指南</a></p><div class="content"><h1 id="PyTorch-深度学习框架快速上手指南"><a href="#PyTorch-深度学习框架快速上手指南" class="headerlink" title="PyTorch 深度学习框架快速上手指南"></a>PyTorch 深度学习框架快速上手指南</h1><p>PyTorch 可以说是目前最常用的深度学习框架 , 常应用于搭建深度学习网络 , 完成一些深度学习任务 (CV、NLP领域)</p>
<p>要想快速上手 PyTorch , 你需要知道什么 :</p>
<ol>
<li>一个项目的完整流程 , 即到什么点该干什么事</li>
<li>几个常用 (或者说必备的) 组件</li>
</ol>
<p>剩下的时间你就需要了解 , 完成什么任务 , 需要什么网络 , 而且需要用大量的时间去做这件事情 <p><br>$^{(e.g.)}$例如 : 你现在有一个<strong>图像分类任务</strong> , 完成该任务需要什么网络, 你需要通过<strong>查找资料</strong>来了解需要查找什么网络。</p>
<p>需要注意的是 , 有一些常识性的问题你必须知道 , 例如: 图像层面无法或很难使用机器学习方法 , 卷积神经网络最多的是应用于图像领域等</p>
<hr>
<h2 id="下面我将通过一个具体的分类项目流程来讲述到什么点该干什么事"><a href="#下面我将通过一个具体的分类项目流程来讲述到什么点该干什么事" class="headerlink" title="下面我将通过一个具体的分类项目流程来讲述到什么点该干什么事"></a>下面我将通过一个具体的<strong>分类项目</strong>流程来讲述<strong>到什么点该干什么事</strong></h2><p>一个完整的 PyTorch 分类项目需要以下几个方面:</p>
<ol>
<li>准备数据集</li>
<li>加载数据集</li>
<li>使用变换(Transforms模块)</li>
<li>构建模型</li>
<li>训练模型 + 验证模型</li>
<li>推理模型</li>
</ol>
<hr>
<ol>
<li><strong>准备数据集</strong> 一般来说 , 比赛会给出你数据集, 不同数据集的组织方式不同 , 我们要想办法把他构造成我们期待的样子<ul>
<li>分类数据集一般比较简单, 一般是将某个分类的文件全都放在一个文件夹中, 例如:</li>
<li>二分类问题 : Fake(文件夹) &#x2F; Real(文件夹)</li>
<li>多分类问题 : 分类 1(文件夹) &#x2F; 分类 2(文件夹) &#x2F; … &#x2F; 分类 N(文件夹)</li>
<li>当然有些时候他们会给出其他方式 , 如 <strong>UBC-OCEAN</strong> , 他们将所有的图片放在一个文件夹中 , 并用 csv 文件存储这些文件的路径(或者是文件名) , 然后在 csv 文件中进行标注(如下): <p><img src="https://img-blog.csdnimg.cn/direct/b8c54d7db30e40b2a99165a3daf72059.png#pic_center"  width = "426" height = "217">
<img src="https://img-blog.csdnimg.cn/direct/e61c1682065e4520a5cc460cff4d78d4.png#pic_center" width = "621" height = "217"></li>
<li>以后你可能还会遇到更复杂的目标检测的数据集, 这种数据集会有一些固定格式 , 如 <strong>VOC格式</strong> , <strong>COCO格式</strong>等</li>
<li>在数据集方面 , 需要明确三个概念——训练集、验证集和测试集 , 请务必明确这三个概念 , 这是<strong>基本中的基本</strong><ul>
<li><em>训练集(Train)</em> : 字如其名 , 简单来说就是<strong>知道数据</strong> , 也<strong>知道标签</strong> 的数据 , 我们用其进行训练</li>
<li><em>验证集(Valid)</em> : <em>验证集</em> 和 <em>测试集</em> 是非常容易混淆的概念 , 简单来说 , 验证集就是我们也<strong>知道数据和标签</strong> , 但是我们的一般不将这些数据用于训练 , 而是将他们当作<strong>我们的测试集</strong> , 即我们已经站在了出题人的角度 , 给出参赛者输入数据 , 而我们知道这个数据对应的输出 , 但是我们不让模型知道</li>
<li><em>测试集(Test)</em> : 测试集就是 , 我们<strong>不知道输入数据的输出标签</strong> , 只有真正的出题人知道 , 一般来说 , 我们无法拿到测试集 , 测试集是由出题人掌控的</li>
<li><strong>需要注意的是</strong> , 如果你通过某种途径知道了所有的测试集的标签时 , 不可使用测试集进行训练 , 这是<strong>非常严重的学术不端行为</strong> , 会被学术界和工业界唾弃</li>
</ul>
</li>
</ul>
</li>
</ol>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 现在我们已经有了一个数据集 , 我将以 FAKE_OR_REAL 数据集为例 , 展示我们数据集的结构</span></span><br><span class="line"><span class="comment"># D:\REAL_OR_FAKE\DATASET</span></span><br><span class="line"><span class="comment"># ├─test --------- 测试集路径, 这里可以放你自己的数据, 你甚至可以将他们分类, 但是请注意, 实际情况下你只能通过这种方式来“得到”测试集</span></span><br><span class="line"><span class="comment"># │  ├─fake ------ 你自己分的类, 开心就好</span></span><br><span class="line"><span class="comment"># │  └─real ------ 同上</span></span><br><span class="line"><span class="comment"># ├─train -------- 训练集路径, 这里面放的是题目给出的数据, 下面有 fake 和 real 两个文件夹, 这两个文件夹中就是两个类别, 我们要用这里面的图片进行分类 </span></span><br><span class="line"><span class="comment"># │  ├─fake</span></span><br><span class="line"><span class="comment"># │  └─real</span></span><br><span class="line"><span class="comment"># └─valid -------- 验证集路径, 这里面放的是题目给出的数据, 下面有 fake 和 real 两个文件夹, 这两个文件夹中就是两个类别, 这里面的图片不需要进行训练</span></span><br><span class="line"><span class="comment">#     ├─fake</span></span><br><span class="line"><span class="comment">#     └─real</span></span><br></pre></td></tr></table></figure>
<ol>
<li><strong>加载数据集</strong><ul>
<li>请务必记住 , 不管是什么数据集 , 数据集是如何构成的 , 在使用 PyTorch 框架时 , 我们都要像尽办法将他们加载入 <strong><code>Dataset</code></strong> 类中</li>
<li>简单来说 , <code>Dataset</code> 类就是描述了我们数据的组成的类</li>
<li>需要注意 , PyTorch 实现了许多自己的 <code>Dataset</code> 类 , 这些类可以轻松的加载<strong>特定格式</strong>的数据集 , 但是我<strong>强烈建议</strong>所有的数据集都要自己继承<strong>Dataset</strong>类 , 自行加载 , 这样我们可以跟清晰的指导数据集的组成方式 , 也可以使得我们加载任意格式的数据集</li>
<li>实现 <code>DataSet</code> 类需要我们先继承 <code>Dataset</code> 类 , 在继承 <code>Dataset</code> 类后, 我们只需要实现其中的<code>__init__</code>、<code>__len__</code>和<code>__getitem__</code>三个方法 , 即可完成对数据集的加载 , 这三个方法就和他的名字一样 : <ul>
<li><code>__init__</code> 方法是<strong>构造函数</strong> , 用于初始化</li>
<li><code>__len__</code> 方法用于获取数据集的大小</li>
<li><code>__getitem__</code> 方法用于获取数据集的元素 , 我将从下面的代码中进行更详细的解释</li>
</ul>
</li>
<li>有些数据集并不分别提供 Train训练集 和 Valid验证集, 我们可以使用 <code>random_split()</code> 方法对数据集进行划分<ul>
<li><p>需要注意的是, 每次重新划分数据集时, 必须重新训练模型, 因为 <code>random_split()</code> 方法随机性, 划分后的数据不可能和之前的数据完全重合, 因此会导致数据交叉的情况, 下面一段使用 <code>random_split()</code> 进行划分的 <strong>Python</strong> 代码示例 :</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下面演示使用 random_split 来划分数据集的操作</span></span><br><span class="line"><span class="comment"># 我们假设已经定义了 CustomImageDataSet</span></span><br><span class="line">split_ratio = <span class="number">0.8</span>                                    <span class="comment"># 表示划分比例为 8 : 2</span></span><br><span class="line">dataset = CustomImageDataSet(fake_dir, real_dir)     <span class="comment"># 定义 CustomImageDataSet 类, 假设此时没有划分训练集和验证集</span></span><br><span class="line">train_dataset_num = <span class="built_in">int</span>(dataset.lens * split_ratio)  <span class="comment"># 定义训练集的大小</span></span><br><span class="line">valid_dataset_num = dataset.lens - train_dataset_num <span class="comment"># 定义验证集的大小</span></span><br><span class="line"><span class="comment"># random_split(dataset, [train_dataset_num, valid_dataset_num]) 表示将 dataset 按照 [train_dataset_num: valid_dataset_num] 的比例进行划分</span></span><br><span class="line">train_dataset, valid_dataset = random_split(dataset, [train_dataset_num, valid_dataset_num])</span><br></pre></td></tr></table></figure>
</li>
<li><p>当数据集不是很大的时, 推荐人为的将数据集进行划分, 可以写一个 <strong>Python 脚本(.py)</strong> 或者 <strong>批处理脚本(.bat)</strong> 来完成这个操作</p>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>完整的数据集加载代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里我们定义了一个 CustomImageDataset(...) 类, 括号中的内容表示我们继承了 ... 类</span></span><br><span class="line"><span class="comment"># 因此我们这里 CustomImageDataset(Dataset): 表示我们定义了一个“自定义图片”类, 这个“自定义图片”类继承自 Dataset 类</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CustomImageDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="comment"># 这里我们实现 __init__ 方法, __init__ 方法其实就是一个类的构造函数, 他也分有参构造和无参构造, 只是在这里我们说无参构造基本没啥意义</span></span><br><span class="line">    <span class="comment"># 因此我们常常实现这个类, 使得可以指定这个类的输入输出</span></span><br><span class="line">    <span class="comment"># 比如下面我们写的 def __init__(self, fake_dir, real_dir, transform=None):</span></span><br><span class="line">    <span class="comment"># self : 自己, 我一般直接理解为 this 指针, 如果有兴趣了解更深层的东西可以查阅一些资料, 这个是必填的</span></span><br><span class="line">    <span class="comment"># fake_dir : 用于指定 fake 类型图片的位置的</span></span><br><span class="line">    <span class="comment"># real_dir : 用于指定 real 类型图片的位置的</span></span><br><span class="line">    <span class="comment"># transform : 用于指定变换, 简单来说就是对输入进行某些操作, 我会在下面的板块中进行详细叙述</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, fake_dir, real_dir, transform=<span class="literal">None</span></span>):</span><br><span class="line">        self.fake_dir = fake_dir        <span class="comment"># 这里表示这个类内定义了一个 fake_dir, 其值为传入的 fake_dir</span></span><br><span class="line">        self.real_dir = real_dir        <span class="comment"># 这里表示这个类内定义了一个 real_dir, 其值为传入的 real_dir</span></span><br><span class="line">        self.transform = transform      <span class="comment"># 这里表示这个类内定义了一个 transform, 其值为传入的 transform, 当没有传入时, 这个变量为 None</span></span><br><span class="line"></span><br><span class="line">        self.fake_images = os.listdir(fake_dir)     <span class="comment"># 传入的 fake_dir 是一个路径, 我们使用 os.listdir(fake_dir) 可以加载 fake_dir 文件夹下的内容, 也就是所有 fake 图片</span></span><br><span class="line">        self.real_images = os.listdir(real_dir)     <span class="comment"># 传入的 real_dir 是一个路径, 我们使用 os.listdir(real_dir) 可以加载 real_dir 文件夹下的内容, 也就是所有 real 图片</span></span><br><span class="line"></span><br><span class="line">        self.total_images = self.fake_images + self.real_images <span class="comment"># 总图片列表, 就是将 fake 图片列表和 real 图片列表进行组合</span></span><br><span class="line">        self.labels = [<span class="number">0</span>]*<span class="built_in">len</span>(self.fake_images) + [<span class="number">1</span>]*<span class="built_in">len</span>(self.real_images) <span class="comment"># 对图片打标签, fake 为 0, real 为 1</span></span><br><span class="line">                                                                            <span class="comment"># [0] * 10 得到的结果为 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</span></span><br><span class="line">                                                                            <span class="comment"># [1] * 10 得到的结果为 [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这里我们实现 __len__ 方法, 这个方法用于获取数据集的大小</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.total_images)   <span class="comment"># 这里我们直接返回总图片列表的长度即可, 这里的实现方式不唯一, 只要能做到表示数据集大小即可</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这里我们实现 __getitem__ 方法, 这个方法用于获取数据集中的某个元素</span></span><br><span class="line">    <span class="comment"># 其中 idx 表示索引, 这个参数是必须的, 当然可以起其他名字, 不过最好还是使用 idx</span></span><br><span class="line">    <span class="comment"># __getitem__(self, idx) 表示获取 idx 位置的元素</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        <span class="comment"># 这里表示获取一个元素的逻辑</span></span><br><span class="line">        <span class="comment"># 当 idx 位置的标签为 0 时, 图片的路径为 fake_dir + self.total_images[idx], idx 即为图片的索引位置</span></span><br><span class="line">        <span class="comment"># 当 idx 位置的标签为 1 时, 图片的路径为 real_dir + self.total_images[idx]</span></span><br><span class="line">        image_path = os.path.join(self.fake_dir <span class="keyword">if</span> self.labels[idx] == <span class="number">0</span> <span class="keyword">else</span> self.real_dir, self.total_images[idx])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 使用 PIL 库加载图片, 通过 image_path 打开图片, 并且将图片转化为 RGB 格式</span></span><br><span class="line">        image = Image.<span class="built_in">open</span>(image_path).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 这里是 transform, 表示变换, 当其值为 None 时不进行操作, 当传入自己的 transform 时即为非空, 即对输入数据进行变换</span></span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            <span class="comment"># 我们将变换后的图片直接保存在原位置</span></span><br><span class="line">            image = self.transform(image)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 最后函数的返回值为 image 和 self.labels[idx], 即表示索引位置 idx 处的图片和标签</span></span><br><span class="line">        <span class="keyword">return</span> image, self.labels[idx]</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><strong>使用 Transforms</strong><ul>
<li>不要简单的使用原始图片进行训练 , 当然如果一定要使用原始图片进行训练, 也可以使用 <strong>transforms</strong> 模块</li>
<li>一般来说, 训练集和验证集的 <strong>transforms</strong> 是不同的, 因为我们希望验证集和测试集的图片贴合真实的情况 </li>
<li>下面的代码演示了如何定义 <strong>transforms</strong></li>
<li>在定义完 <code>transforms</code> 我们就可以完全定义我们的 <code>Dataset</code> 和 <code>Dataloader</code> 了</li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义transform</span></span><br><span class="line"><span class="comment"># transforms.Compose(transforms) 实际上就是将多个 transform 方法变为逐步执行, 一般我们直接使用这种方式来对图片进行连续的变换</span></span><br><span class="line">train_transform = transforms.Compose([</span><br><span class="line">    transforms.RandomHorizontalFlip(),                                      <span class="comment"># 随机水平翻转</span></span><br><span class="line">    transforms.RandomVerticalFlip(),                                        <span class="comment"># 随机垂直翻转</span></span><br><span class="line">    transforms.ColorJitter(brightness=<span class="number">0.1</span>, contrast=<span class="number">0.1</span>, saturation=<span class="number">0.1</span>),   <span class="comment"># 改变图像的属性, 将图像的brightness亮度/contrast对比度/saturation饱和度/hue色相 随机变化为原图亮度的 10%</span></span><br><span class="line">    transforms.RandomResizedCrop(<span class="number">224</span>, scale=(<span class="number">0.8</span>, <span class="number">1.0</span>)),                    <span class="comment"># 对图片先进行随机采集, 然后对裁剪得到的图像缩放为同一大小, 意义是即使只是该物体的一部分, 我们也认为这是该类物体</span></span><br><span class="line">    transforms.RandomRotation(<span class="number">40</span>),                                          <span class="comment"># 在[-40, 40]范围内随机旋转</span></span><br><span class="line">    transforms.RandomAffine(degrees=<span class="number">0</span>, shear=<span class="number">10</span>, scale=(<span class="number">0.8</span>,<span class="number">1.2</span>)),          <span class="comment"># 随机仿射变换</span></span><br><span class="line">    transforms.ColorJitter(brightness=<span class="number">0.2</span>, contrast=<span class="number">0.2</span>, saturation=<span class="number">0.2</span>),   <span class="comment"># 色彩抖动</span></span><br><span class="line">    transforms.ToTensor(),                                                  <span class="comment"># [重点] 将图片转化为 Tensor 张量, 在 PyTorch 中, 一切的运算都基于张量, 请一定将你的输入数据转化为张量</span></span><br><span class="line">                                                                            <span class="comment"># 请理解什么是张量 : 我们在线性代数中有向量的概念, 简单来说就是张量就是向量, 只不过张量往往具有更高的维度</span></span><br><span class="line">                                                                            <span class="comment"># 而大家一般习惯将高于三维的向量称为张量, 某些人(比如我)也习惯所有的向量统称为张量</span></span><br><span class="line">                                                                            <span class="comment"># 可以简单的将数组的维数来界定张量的维度</span></span><br><span class="line">                                                                            <span class="comment"># 例如 [ ] 为一维张量, [[ ]] 为二维张量, [[[ ]]]为三维张量, [[[[ ]]]]为四维张量</span></span><br><span class="line">                                                                            <span class="comment"># 对于图像来说, jpg 图像实际为三维矩阵, png 图像实际为四维矩阵, 这个维数是根据图像的通道数进行划分的</span></span><br><span class="line">                                                                            <span class="comment"># 例如 jpg 有 R、G、B三个通道, png 具有 </span></span><br><span class="line">    transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]),    <span class="comment"># 归一化, 可以对矩阵进行归一化</span></span><br><span class="line">                                                                                    <span class="comment"># 详细查看这个Blog : https://blog.csdn.net/qq_38765642/article/details/109779370</span></span><br><span class="line">    transforms.RandomErasing()                                              <span class="comment"># 随机擦除</span></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">valid_transform = transforms.Compose([</span><br><span class="line">    transforms.Resize((<span class="number">256</span>, <span class="number">256</span>)),                                          <span class="comment"># Resize 操作, 将图片转换到指定的大小</span></span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 Dataset 实例</span></span><br><span class="line">train_dataset = CustomImageDataset(fake_dir=<span class="string">&quot;./dataset/train/fake&quot;</span>, real_dir=<span class="string">&quot;./dataset/train/real&quot;</span>, transform=train_transform)</span><br><span class="line">valid_dataset = CustomImageDataset(fake_dir=<span class="string">&quot;./dataset/valid/fake&quot;</span>, real_dir=<span class="string">&quot;./dataset/valid/real&quot;</span>, transform=valid_transform)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 DataLoader 实例</span></span><br><span class="line"><span class="comment"># 这里将要涉及到超参数的概念, 什么是超参数: 简单来将, 超参数就是我们自己能指定的一些数据, 超参数的选择将很大程度上影响模型的性能</span></span><br><span class="line"><span class="comment"># 因此 深度学习领域的工程师 常称自己为 炼丹师、调参师等</span></span><br><span class="line">batch_size = <span class="number">32</span> <span class="comment"># batch_size 就是一个超参数, batch 即为 “批次”, 表示一次使用 DataLoader 加载多少张图片进行运算</span></span><br><span class="line">                <span class="comment"># 这个数值并不是越大越好, 也不是越小越好, 但是往往大一些比较好, 这个数字最大能选择多大和你的图片大小和显卡显存有很大的关系</span></span><br><span class="line">                <span class="comment"># 当出现 [Out Of Memery] 错误时往往表明你选取了过大的 batch_size, 导致显卡出现了爆显存的问题</span></span><br><span class="line"><span class="comment"># batch_size : 每次训练时，模型所看到的数据数量。它是决定训练速度和内存使用的重要参数。</span></span><br><span class="line"><span class="comment"># shuffle : 是否在每个训练周期之前打乱数据集的顺序。这对于许多模型（如卷积神经网络）是很有帮助的，因为它可以帮助模型避免模式识别。</span></span><br><span class="line"><span class="comment"># sampler : 定义如何从数据集中抽样。默认情况下，它使用随机采样。但你可以使用其他更复杂的采样策略，如学习率调度采样。</span></span><br><span class="line"><span class="comment"># batch_sampler : 与sampler类似，但它在批处理级别上进行采样，而不是在整个数据集上。这对于内存使用效率更高的场景很有用。</span></span><br><span class="line"><span class="comment"># num_workers : 定义了多少个工作进程用于数据的加载。这可以加快数据加载的速度，但需要注意内存的使用情况。</span></span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line">valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看Dataloader数据</span></span><br><span class="line"><span class="comment"># 为了了解Dataloader中的数据, 我们可以使用以下方法来查看:</span></span><br><span class="line"><span class="comment"># 使用 Python 的 len() 函数 : 我们可以直接通过 len() 函数获取 Dataloader 的长度, 即数据集中数据块的数量</span></span><br><span class="line"><span class="comment"># 使用 torch.utils.data.DataLoader.len() 方法 : 这个方法也会返回Dataloader的长度。</span></span><br><span class="line"><span class="comment"># 使用 iter() 函数：Dataloader是一个可迭代对象，我们可以直接通过iter()函数对其进行迭代，以获取每个批次的数据。</span></span><br><span class="line"><span class="comment"># 使用torchvision.utils.save_image()函数 : 如果我们正在处理的是图像数据集，那么可以使用这个函数来保存Dataloader中的图像数据。                </span></span><br><span class="line"><span class="built_in">len</span>(train_loader)   <span class="comment"># 401</span></span><br><span class="line"><span class="built_in">len</span>(valid_loader)   <span class="comment"># 100</span></span><br><span class="line">images, labels = <span class="built_in">next</span>(<span class="built_in">iter</span>(train_loader))</span><br><span class="line"><span class="built_in">print</span>(images)</span><br><span class="line"><span class="built_in">print</span>(labels)</span><br></pre></td></tr></table></figure>

<ol start="4">
<li><strong>构建模型</strong><ul>
<li>构建模型是比较重要的一部分, 一般来说做好数据集之后, 最重要的事情就是修改模型, 通过训练结果改进模型, 判断自己的模型的正确性, 这里就是整个你要用到的神经网络的部分 , 需要注意的是 , 这里指定什么输入 , 推理的时候就要指定什么输入</li>
<li>简单用几个符号说明一下就是: $^{Train} model (inputX, inputY, …)$ → $^{Valid} model (inputX, inputY, …)$<ul>
<li>如何确定输入是什么: 看 <strong><code>forward()</code></strong> 的输入是啥模型的输入就是啥</li>
</ul>
</li>
<li>我下面展现了我复现的 <strong>ResNet50</strong> , 用这种方式可以顺便教你如何复现网络结构</li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里是对 ResNet50 的实现, 请对照论文来进行对照阅读</span></span><br><span class="line"><span class="comment"># 定义 ResNet50Basic类, 这里并不是完整的模型, 而是模型的一个部分</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet50BasicBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, outs, kernerl_size, stride, padding</span>):</span><br><span class="line">        <span class="comment"># super(ResNet50BasicBlock, self).__init__() 这里是干什么的?</span></span><br><span class="line">        <span class="comment"># 1. 首先找到 ResNet50BasicBlock 的父类, 这里是 nn.Module</span></span><br><span class="line">        <span class="comment"># 2. 把类 ResNet50BasicBlock 的对象self转换为 nn.Module 的对象</span></span><br><span class="line">        <span class="comment"># 3. &quot;被转换&quot;的 nn.Module 对象调用自己的 init 函数</span></span><br><span class="line">        <span class="comment"># 简单理解一下就是 : 子类把父类的 __init__ 放到自己的 __init__ 当中, 这样子类就有了父类的 __init__ 的那些东西</span></span><br><span class="line">        <span class="built_in">super</span>(ResNet50BasicBlock, self).__init__()</span><br><span class="line">        <span class="comment"># 这里只是定义部分, 在这里的定义并不一定会在推理过程中使用</span></span><br><span class="line">        self.conv1 = nn.Conv2d(in_channel, outs[<span class="number">0</span>], kernel_size=kernerl_size[<span class="number">0</span>], stride=stride[<span class="number">0</span>], padding=padding[<span class="number">0</span>])</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(outs[<span class="number">0</span>])</span><br><span class="line">        self.conv2 = nn.Conv2d(outs[<span class="number">0</span>], outs[<span class="number">1</span>], kernel_size=kernerl_size[<span class="number">1</span>], stride=stride[<span class="number">0</span>], padding=padding[<span class="number">1</span>])</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(outs[<span class="number">1</span>])</span><br><span class="line">        self.conv3 = nn.Conv2d(outs[<span class="number">1</span>], outs[<span class="number">2</span>], kernel_size=kernerl_size[<span class="number">2</span>], stride=stride[<span class="number">0</span>], padding=padding[<span class="number">2</span>])</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(outs[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输入是啥看 forward(), 例如这里是 forward(self, x), 则表示输入是 x, 也就是一个</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># nn.Conv2d 是卷积层, 请了解[1]什么是卷积层, 以及[2]卷积层是干啥用的, [3]卷积后会变成什么</span></span><br><span class="line">        <span class="comment"># 卷积运算的目的是提取输入的不同特征, 第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级, 更多层的网路能从低级特征中迭代提取更复杂的特征</span></span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        <span class="comment"># [*] 什么是 ReLU, ReLU是激活函数, 请了解 [1]什么是激活函数, [2]为什么要使用激活函数</span></span><br><span class="line">        <span class="comment"># [*] 什么是 Batch Normalization层, BN 层是批次归一化层</span></span><br><span class="line">        out = F.relu(self.bn1(out))</span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = F.relu(self.bn2(out))</span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.bn3(out)</span><br><span class="line">        <span class="keyword">return</span> F.relu(out + x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 ResNet50DownBlock类, 这里并不是完整的模型, 而是模型的一个部分</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet50DownBlock</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channel, outs, kernel_size, stride, padding</span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet50DownBlock, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channel, outs[<span class="number">0</span>], kernel_size=kernel_size[<span class="number">0</span>], stride=stride[<span class="number">0</span>], padding=padding[<span class="number">0</span>])</span><br><span class="line">        self.bn1 = nn.BatchNorm2d(outs[<span class="number">0</span>])</span><br><span class="line">        self.conv2 = nn.Conv2d(outs[<span class="number">0</span>], outs[<span class="number">1</span>], kernel_size=kernel_size[<span class="number">1</span>], stride=stride[<span class="number">1</span>], padding=padding[<span class="number">1</span>])</span><br><span class="line">        self.bn2 = nn.BatchNorm2d(outs[<span class="number">1</span>])</span><br><span class="line">        self.conv3 = nn.Conv2d(outs[<span class="number">1</span>], outs[<span class="number">2</span>], kernel_size=kernel_size[<span class="number">2</span>], stride=stride[<span class="number">2</span>], padding=padding[<span class="number">2</span>])</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(outs[<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">        self.extra = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channel, outs[<span class="number">2</span>], kernel_size=<span class="number">1</span>, stride=stride[<span class="number">3</span>], padding=<span class="number">0</span>),</span><br><span class="line">            nn.BatchNorm2d(outs[<span class="number">2</span>])</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x_shortcut = self.extra(x)</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.bn1(out)</span><br><span class="line">        out = F.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        out = self.bn2(out)</span><br><span class="line">        out = F.relu(out)</span><br><span class="line"></span><br><span class="line">        out = self.conv3(out)</span><br><span class="line">        out = self.bn3(out)</span><br><span class="line">        <span class="keyword">return</span> F.relu(x_shortcut + out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet50</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet50, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>)</span><br><span class="line">        self.maxpool = nn.MaxPool2d(kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Sequential 类是 torch.nn 模块中的一个容器, 可以将多个层封装在一个对象中, 方便顺序连接</span></span><br><span class="line">        self.layer1 = nn.Sequential(</span><br><span class="line">            ResNet50DownBlock(<span class="number">64</span>, outs=[<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], kernel_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">            ResNet50BasicBlock(<span class="number">256</span>, outs=[<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], kernerl_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">            ResNet50BasicBlock(<span class="number">256</span>, outs=[<span class="number">64</span>, <span class="number">64</span>, <span class="number">256</span>], kernerl_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.layer2 = nn.Sequential(</span><br><span class="line">            ResNet50DownBlock(<span class="number">256</span>, outs=[<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], kernel_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">            ResNet50BasicBlock(<span class="number">512</span>, outs=[<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], kernerl_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">            ResNet50BasicBlock(<span class="number">512</span>, outs=[<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], kernerl_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">            ResNet50DownBlock(<span class="number">512</span>, outs=[<span class="number">128</span>, <span class="number">128</span>, <span class="number">512</span>], kernel_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.layer3 = nn.Sequential(</span><br><span class="line">            ResNet50DownBlock(<span class="number">512</span>, outs=[<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], kernel_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">            ResNet50BasicBlock(<span class="number">1024</span>, outs=[<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], kernerl_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">            ResNet50BasicBlock(<span class="number">1024</span>, outs=[<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], kernerl_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">            ResNet50DownBlock(<span class="number">1024</span>, outs=[<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], kernel_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">            ResNet50DownBlock(<span class="number">1024</span>, outs=[<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], kernel_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">            ResNet50DownBlock(<span class="number">1024</span>, outs=[<span class="number">256</span>, <span class="number">256</span>, <span class="number">1024</span>], kernel_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.layer4 = nn.Sequential(</span><br><span class="line">            ResNet50DownBlock(<span class="number">1024</span>, outs=[<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], kernel_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">            ResNet50DownBlock(<span class="number">2048</span>, outs=[<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], kernel_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]),</span><br><span class="line">            ResNet50DownBlock(<span class="number">2048</span>, outs=[<span class="number">512</span>, <span class="number">512</span>, <span class="number">2048</span>], kernel_size=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>], stride=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        self.avgpool = nn.AvgPool2d(kernel_size=<span class="number">7</span>, stride=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># self.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))</span></span><br><span class="line"></span><br><span class="line">        self.fc = nn.Linear(<span class="number">2048</span>, <span class="number">10</span>)</span><br><span class="line">        <span class="comment"># 使用卷积代替全连接</span></span><br><span class="line">        self.conv11 = nn.Conv2d(<span class="number">2048</span>, <span class="number">10</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.maxpool(out)</span><br><span class="line">        out = self.layer1(out)</span><br><span class="line">        out = self.layer2(out)</span><br><span class="line">        out = self.layer3(out)</span><br><span class="line">        out = self.layer4(out)</span><br><span class="line">        <span class="comment"># avgpool 平均池化层, 了解什么是平均池化层</span></span><br><span class="line">        out = self.avgpool(out)</span><br><span class="line">        out = self.conv11(out)</span><br><span class="line">        out = out.reshape(x.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># out = self.fc(out)</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里展现了对 ResNet 的一个具体的应用</span></span><br><span class="line"><span class="comment"># x = torch.randn(1, 3, 224, 224)   # 这个是我们 ResNet50 期待的输入样子, 可以看到他是 [1] 个 [3] 通道, 宽度为[224], 高度为 [224]的张量 </span></span><br><span class="line">image_path = <span class="string">&#x27;./dataset/test/fake/test_fake_1.png&#x27;</span></span><br><span class="line">image = Image.<span class="built_in">open</span>(image_path).convert(<span class="string">&#x27;RGB&#x27;</span>)   <span class="comment"># 图片加载</span></span><br><span class="line">transform = transforms.ToTensor()               <span class="comment"># 将图片转化为张量, 此时的 张量的形状为[3, 1024, 1024]</span></span><br><span class="line"><span class="comment"># 当输入数据的维度不足时, 我们可以通过 unsqueeze() 添加维度, 这个东西简单理解一下就是, 在某个维度外面加括号[], 即可拓展出更高的维度</span></span><br><span class="line">img_tensor = transform(image).unsqueeze(dim=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># print(x.shape) 我们可以使用 shape 来查看一个张量的形状</span></span><br><span class="line"><span class="comment"># print(img_tensor.shape)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里加载我们的网络架构</span></span><br><span class="line">net = ResNet50()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里进行输入, 输入 img_tensor, 进入 forword() 部分, 然后得到最终输出的结果</span></span><br><span class="line">out = net(img_tensor)</span><br><span class="line"><span class="built_in">print</span>(out)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这里为了方便, 我们直接加载 PyTorch 预训练好的 ResNet50 的模型</span></span><br><span class="line"><span class="comment"># PyTorch 已经为我们提供了不少已经预训练好的模型, 我们只需要加载他们与训练好的模型即可</span></span><br><span class="line"><span class="comment"># 但是我还是希望你可以掌握上面这种自定义模型的方法, 这样遇到 PyTorch 未提供的模型, 我们也可以尝试自己实现该模型</span></span><br><span class="line">model = models.resnet50(pretrained=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 冻结参数 : 即不更新模型的参数</span></span><br><span class="line"><span class="comment"># 可以看到下面的代码, 这里表示冻结了所有层</span></span><br><span class="line"><span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">    param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 但是我们可以通过替换层来接触某些层的冻结</span></span><br><span class="line">num_ftrs = model.fc.in_features         <span class="comment"># 这里是获取 ResNet50 的 fc 层的输入特征数</span></span><br><span class="line">model.fc = torch.nn.Linear(num_ftrs, <span class="number">2</span>) <span class="comment"># 这里是对 fc 层进行修改, Linear(input_feather_num, output_feather_num)</span></span><br><span class="line">                                        <span class="comment"># 这里输入特征数是 num_ftrs, 输出特征数为 2 </span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 这一行很重要, 指定了模型的位置, cuda 可以理解为 GPU 设备, cuda: 0 表示使用编号为 0 的GPU进行训练</span></span><br><span class="line"><span class="comment"># 当有多块 GPU 时, 可以用其他的方式指定 GPU</span></span><br><span class="line"><span class="comment"># model = torch.nn.DataParallel(model, device_ids=[0, 1, 2]), 当然向我们这种小白(穷B), 当然还是单卡为主</span></span><br><span class="line"><span class="comment"># 为了避免出现多卡的情况, 我在下面放入两篇博客, 有兴趣可以参考这两篇文章进行多卡训练</span></span><br><span class="line"><span class="comment"># https://zhuanlan.zhihu.com/p/102697821</span></span><br><span class="line"><span class="comment"># https://blog.csdn.net/qq_34243930/article/details/106695877</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">model = model.to(device)</span><br></pre></td></tr></table></figure>

<ol start="5">
<li><strong>训练模型 + 验证模型</strong><ul>
<li>这里需要直接对模型进行训练 , 一般来说 , 在训练的过程中我们会加入 <strong>tqdm</strong> 库使得训练过程可视化 , 有时我们还会在训练过程中保存更好的训练结果 , 并且设置断点训练等操作 , 我只使用最简单的方式进行预测</li>
<li><code>train</code> 部分的代码因人而异, 基本上每个人的写法都可能不同, 没有固定的写法</li>
<li>对于训练完的模型我们需要对其进行评价, 一般来说, 训练和验证都是放在一起的, 不可分开的</li>
<li>记得保存一下训练后的模型, 使用如下代码保存&#x2F;加载整个模型<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">model_path = <span class="string">&quot;xxxx.pth&quot;</span>        <span class="comment"># xxxx 表示一个你喜欢的名字</span></span><br><span class="line">torch.save(model, model_path)  <span class="comment"># 使用 torch.save(model, model_path) 保存模型</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型</span></span><br><span class="line">model = torch.load(model_path) <span class="comment"># 使用 torch.load(model_path) 即可加载模型</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<p>完整的”训练模型 + 验证模型”代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> f1_score, accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line"><span class="comment"># 这里包含了 PyTorch 的 19 种损失函数 https://blog.csdn.net/qq_35988224/article/details/112911110</span></span><br><span class="line">criterion = torch.nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算 F1 值和 准确率</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">loader, model</span>):</span><br><span class="line">    preds = []</span><br><span class="line">    targets = []</span><br><span class="line">    loop = tqdm(loader, total=<span class="built_in">len</span>(loader), leave=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> loop:</span><br><span class="line">        images, labels = images.to(device), labels.to(device)</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            outputs = model(images)</span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">        preds.extend(predicted.cpu().numpy())</span><br><span class="line">        targets.extend(labels.cpu().numpy())</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Update the progress bar</span></span><br><span class="line">        loop.set_description(<span class="string">&quot;Evaluating&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> f1_score(targets, preds), accuracy_score(targets, preds)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练循环</span></span><br><span class="line">best_f1 = <span class="number">0.0</span></span><br><span class="line">loss_values = []</span><br><span class="line">num_epochs = <span class="number">10</span>     <span class="comment"># 定义训练的轮次</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    model.train()   <span class="comment"># 将模型设置为训练模式</span></span><br><span class="line">    loop = tqdm(train_loader, total=<span class="built_in">len</span>(train_loader), leave=<span class="literal">True</span>)</span><br><span class="line">    <span class="built_in">print</span>(loop)</span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> loop:</span><br><span class="line">        images, labels = images.to(device), labels.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 前向推理</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 反向传播及优化</span></span><br><span class="line">        <span class="comment"># 在用 PyTorch训练模型时, 通常会在遍历 Epochs 的过程中依次用到 </span></span><br><span class="line">        <span class="comment"># optimizer.zero_grad() : 先将梯度归零</span></span><br><span class="line">        <span class="comment"># loss.backward() : 反向传播计算得到每个参数的梯度值</span></span><br><span class="line">        <span class="comment"># optimizer.step() : 通过梯度下降执行一步参数更新</span></span><br><span class="line">        <span class="comment"># 对于这三个函数, 这篇博客写的很好 : https://blog.csdn.net/PanYHHH/article/details/107361827</span></span><br><span class="line">        <span class="comment"># 可以简单阅读一遍</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 保存该批次的损失</span></span><br><span class="line">        loss_values.append(loss.item())</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新进度条</span></span><br><span class="line">        loop.set_description(<span class="string">f&quot;Epoch [<span class="subst">&#123;epoch + <span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>]&quot;</span>)</span><br><span class="line">        loop.set_postfix(loss=loss.item())</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 在每轮之后验证模型</span></span><br><span class="line">    model.<span class="built_in">eval</span>()    <span class="comment"># 将模型设置为推理模式, 此时模型中的参数不会进行更新, 即完全用于推理/验证</span></span><br><span class="line">    f1_value, accuracy = evaluate(valid_loader, model)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;F1 score: <span class="subst">&#123;f1_value:<span class="number">.4</span>f&#125;</span>, Accuracy: <span class="subst">&#123;accuracy:<span class="number">.4</span>f&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存 F1 值最高的模型</span></span><br><span class="line">    <span class="keyword">if</span> f1_value &gt; best_f1:</span><br><span class="line">        best_f1 = f1_value</span><br><span class="line">        <span class="comment"># 这里和上面 Markdown 的保存方式不同, model.state_dict(), 表示模型的参数, 简单来说呢我们仅仅保存了模型的参数, 但是我们并没有保存模型的结构</span></span><br><span class="line">        <span class="comment"># 上面 Markdown 的保存方式是即保存了整个模型的结构, 也保存了模型的参数</span></span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&#x27;best_model.pth&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;训练结束&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>当然我们也可以使用绘图函数，来展示过程中的相关数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">plt.plot(loss_values, label=<span class="string">&#x27;Train Loss&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Loss values over epochs&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Epochs&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<ol start="6">
<li><strong>推理模型</strong><ul>
<li>很高兴, 如果你到这一步, 你的水平肯定已经有了质的飞跃, 这里已经是最后一步了, 结束这个部分, 你就要开始自己的探索之路了 </li>
<li>推理模型很简单, 我在上面说过, 构造模型时指定什么输入 , 推理的时候就要指定什么输入, 这里就是对应的部分了</li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torchvision.transforms <span class="keyword">import</span> ToTensor, Resize, Normalize</span><br><span class="line"></span><br><span class="line"><span class="comment"># predict_by_file 表示推理一个文件, 我们需要传入文件路径以及模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_by_file</span>(<span class="params">file_path, model</span>):</span><br><span class="line">    <span class="comment"># </span></span><br><span class="line">    image = Image.<span class="built_in">open</span>(file_path).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 这里的 transform 有与没有都无所谓, 纯看心情</span></span><br><span class="line">    transform = transforms.Compose([</span><br><span class="line">        Resize((<span class="number">256</span>, <span class="number">256</span>)),</span><br><span class="line">        ToTensor(),</span><br><span class="line">        Normalize(mean=[<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>], std=[<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    image = transform(image)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 这里和上面一样, 表示在最外面加一层括号, 使 [3, 256, 256] 变为 [1, 3, 256, 256]</span></span><br><span class="line">    image = image.unsqueeze(<span class="number">0</span>).to(device)</span><br><span class="line"></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        outputs = model(image)      <span class="comment"># 模型推理</span></span><br><span class="line">        <span class="comment"># torch.max(...)</span></span><br><span class="line">        <span class="comment"># input (Tensor) – 输入张量</span></span><br><span class="line">        <span class="comment"># dim (int) – 指定的维度</span></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)    <span class="comment"># 返回指定维度的最大值, 其实这里只有一维</span></span><br><span class="line">        <span class="built_in">print</span>(outputs)                          <span class="comment"># tensor([[0.7360, 0.2668]], device=&#x27;cuda:0&#x27;)</span></span><br><span class="line">        <span class="built_in">print</span>(outputs.shape)                    <span class="comment"># torch.Size([1, 2])</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;Fake&quot;</span> <span class="keyword">if</span> predicted.item() == <span class="number">0</span> <span class="keyword">else</span> <span class="string">&quot;Real&quot;</span></span><br><span class="line"></span><br><span class="line">path = <span class="string">&#x27;./dataset/test/real/test_real_7.jpg&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(predict_by_file(path, model))</span><br></pre></td></tr></table></figure></div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatarMyself.jpg" alt="NilEra"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">NilEra</p><p class="is-size-6 is-block">C/C++ Developer!</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Jinan Shandong</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">24</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">25</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">28</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/NilEra-K" target="_blank" rel="noopener">关注我</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/NilEra-K"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">链接</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://github.com/NilEra-K" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">GitHub</span></span><span class="level-right"><span class="level-item tag">github.com</span></span></a></li><li><a class="level is-mobile" href="https://nano.chemtian.top/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Thymol Blue</span></span><span class="level-right"><span class="level-item tag">nano.chemtian.top</span></span></a></li></ul></div></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/CppDev/"><span class="level-start"><span class="level-item">CppDev</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/CppDev/Gaming/"><span class="level-start"><span class="level-item">Gaming</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/CppDev/QT6/"><span class="level-start"><span class="level-item">QT6</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/Linux/%E8%BD%AF%E4%BB%B6%E6%BA%90/"><span class="level-start"><span class="level-item">软件源</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"><span class="level-start"><span class="level-item">大数据技术</span></span><span class="level-end"><span class="level-item tag">8</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/ECharts/"><span class="level-start"><span class="level-item">ECharts</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/HBase/"><span class="level-start"><span class="level-item">HBase</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/Scala/"><span class="level-start"><span class="level-item">Scala</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/Spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/"><span class="level-start"><span class="level-item">数据可视化</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/%E9%A1%B9%E7%9B%AE/"><span class="level-start"><span class="level-item">项目</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"><span class="level-start"><span class="level-item">开发工具</span></span><span class="level-end"><span class="level-item tag">3</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/Axure-RP-9/"><span class="level-start"><span class="level-item">Axure RP 9</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/Git/"><span class="level-start"><span class="level-item">Git</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/VSCode/"><span class="level-start"><span class="level-item">VSCode</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构/算法</span></span><span class="level-end"><span class="level-item tag">4</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/%E5%93%88%E5%B8%8C-Hash/"><span class="level-start"><span class="level-item">哈希(Hash)</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/%E6%A0%88-Stack/"><span class="level-start"><span class="level-item">栈(Stack)</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%AE%97%E6%B3%95/%E6%A0%91-Tree/"><span class="level-start"><span class="level-item">树(Tree)</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="level-start"><span class="level-item">深度学习</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/Kaggle/"><span class="level-start"><span class="level-item">Kaggle</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/PyTorch/"><span class="level-start"><span class="level-item">PyTorch</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/%E9%97%B2%E8%81%8A/"><span class="level-start"><span class="level-item">闲聊</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/%E9%97%B2%E8%81%8A/%E8%AE%A1%E5%88%92/"><span class="level-start"><span class="level-item">计划</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">订阅更新</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="订阅"></div></div></form></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-06-23T04:27:44.000Z">2024-06-23</time></p><p class="title"><a href="/2024/06/23/CppGamingDEV-PVZ-BASE-EASYX/">CppGamingDEV_PVZ_BASE_EASYX</a></p><p class="categories"><a href="/categories/CppDev/">CppDev</a> / <a href="/categories/CppDev/Gaming/">Gaming</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-06-22T08:15:12.000Z">2024-06-22</time></p><p class="title"><a href="/2024/06/22/DataVisualization-USE-R-ECHARTS/">DataVisualization_USE_R_ECHARTS</a></p><p class="categories"><a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/">大数据技术</a> / <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96/">数据可视化</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-06-22T07:55:58.000Z">2024-06-22</time></p><p class="title"><a href="/2024/06/22/HBaseExamReview/">HBaseExamReview</a></p><p class="categories"><a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/">大数据技术</a> / <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/HBase/">HBase</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-06-12T07:13:57.000Z">2024-06-12</time></p><p class="title"><a href="/2024/06/12/SparkQuickIN/">SparkQuickIN</a></p><p class="categories"><a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/">大数据技术</a> / <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/Spark/">Spark</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-06-11T08:03:22.000Z">2024-06-11</time></p><p class="title"><a href="/2024/06/11/OnlineTravelBigdataPlatform/">OnlineTravelBigdataPlatform</a></p><p class="categories"><a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/">大数据技术</a> / <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/%E9%A1%B9%E7%9B%AE/">项目</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/06/"><span class="level-start"><span class="level-item">六月 2024</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/05/"><span class="level-start"><span class="level-item">五月 2024</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/04/"><span class="level-start"><span class="level-item">四月 2024</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2024/03/"><span class="level-start"><span class="level-item">三月 2024</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Axure-RP-9/"><span class="tag">Axure RP 9</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CppDev/"><span class="tag">CppDev</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ECharts/"><span class="tag">ECharts</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/EasyX/"><span class="tag">EasyX</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GameDev/"><span class="tag">GameDev</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Git/"><span class="tag">Git</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HBase/"><span class="tag">HBase</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hadoop/"><span class="tag">Hadoop</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Kaggle/"><span class="tag">Kaggle</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/PyTorch/"><span class="tag">PyTorch</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/QT6/"><span class="tag">QT6</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/R/"><span class="tag">R</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Scala/"><span class="tag">Scala</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Spark/"><span class="tag">Spark</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tomcat/"><span class="tag">Tomcat</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/VSCode/"><span class="tag">VSCode</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ZooKeeper/"><span class="tag">ZooKeeper</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%8A%80%E6%9C%AF/"><span class="tag">大数据技术</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"><span class="tag">开发工具</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"><span class="tag">数据结构</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="tag">深度学习</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%AE%A1%E5%88%92/"><span class="tag">计划</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E8%BD%AF%E4%BB%B6%E6%BA%90/"><span class="tag">软件源</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%97%B2%E8%81%8A/"><span class="tag">闲聊</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E9%A1%B9%E7%9B%AE/"><span class="tag">项目</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/StarLogo.svg" alt="Hello, NilEra :-)" height="28"></a><p class="is-size-7"><span>&copy; 2024 NilEra</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p><p class="is-size-7">© 2024 前方⚡高能</p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/NilEra-K"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("zh-cn");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/cookieconsent/3.1.1/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/javascript" id="MathJax-script" async>MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      },
      chtml: {
        matchFontHeight: false
      }
    };</script><script src="https://cdnjs.loli.net/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js"></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container" id="algolia-input"></div><div id="algolia-poweredby" style="display:flex;margin:0 .5em 0 1em;align-items:center;line-height:0"></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div><div class="searchbox-footer"></div></div></div><script src="https://cdnjs.loli.net/ajax/libs/algoliasearch/4.0.3/algoliasearch-lite.umd.js" crossorigin="anonymous" defer></script><script src="https://cdnjs.loli.net/ajax/libs/instantsearch.js/4.3.1/instantsearch.production.min.js" crossorigin="anonymous" defer></script><script src="/js/algolia.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadAlgolia({"applicationId":"2TB5ZZYPCO","apiKey":"00a43f1d62ca7b24c8b78d5f0223c065","indexName":"dev_nilera_blog"}, {"hint":"想要查找什么...","no_result":"未找到搜索结果","untitled":"(无标题)","empty_preview":"(无内容预览)"});
        });</script></body></html>